[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Omics Data Handling and Visualization in R",
    "section": "",
    "text": "Omics Data Handling and Visualization in R\n17 May 2023\nFaculty of Science, Prince of Songkla University\n¬†\n\nBasic R programming for intermediate learner\nExploratory data analysis\nOmics data handling with Tidyverse bundle\nLearn graphical requirements for publications\nGenerating publication-quality plots\n\n\n\n\n\n\nFigure modified from @storyset. Designed by Freepik. Find more R hex stickers at RStudio hex stickers."
  },
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Schedule",
    "section": "",
    "text": "This page contains an updated agenda for the Data Handling and Visualization in R workshop, as well as the speakers and our teaching assistants.\nüìÖ May 17th, 2023 üìçBSc0303, BSc bldg., Faculty of Science, PSU\n\n\n\nTime\nTopic\nMaterials\nSpeaker\nTA\n\n\n\n\n8:30 - 9:00\nRegistration\n\n\n\n\n\n9:00 - 9:30\nWelcome, Introduction, and Graphical Requirement for Article Submission\nüìñ\nPS\n\n\n\n9:30 - 10:20\nBasic R Programming\nüìñ\nPS, JN\nPY, KC\n\n\n10:20 - 10:30\nMorning Break\n\n\n\n\n\n10:30 - 11:15\nExploratory Data Analysis with R\nüìñ\nPS, JN\nPY, KC\n\n\n11:15 - 12:00\n\nGrammar of Graphics\nDirectory of Data Visualization\n\nüìñ\nüìñ\nPS, JN\nPY, KC\n\n\n12:00 - 13:00\nLunch\n\n\n\n\n\n13:00 - 14:15\nPlotting Omics Data (1)\nüìñ\nPS, JN\nPY, KC\n\n\n14:15 - 14:30\nAfternoon Break\n\n\n\n\n\n14:30 - 15:30\nPlotting Omics Data (2)\nüìñ\nPS, JN\nPY, KC\n\n\n15:30 - 16:00\nArranging Multiple Plots and Figures\nüìñ\nPS, JN\nPY, KC\n\n\n16:00 - 16:15\nQ & A\n\nEveryone\nEveryone\n\n\n16:15 - 16:30\nClosing and Feedback Session\n\nEveryone\nEveryone\n\n\n\n\nüì¢ Speakers & TA team\n\n\n\n\n\n\n\nPS: Ponsit Sathapondecha, JN: Jiratchaya Nuanpirom, PY: Prasert Yodsawat, KC: Khunanon Chanasongkhram"
  },
  {
    "objectID": "prerequisite.html",
    "href": "prerequisite.html",
    "title": "Prerequisites",
    "section": "",
    "text": "WindowsmacOS\n\n\n\nOS: Windows 10/11\nMemory: &gt; 8 GB RAM\nROM: storage using Solid-state drive (SSD) is preferable. (Here‚Äôs how to check)\n\n\n\n\nOS: macOS 11 (Big Sur) or higher\nMemory: &gt; 8 GB RAM"
  },
  {
    "objectID": "prerequisite.html#minimum-system-requirements",
    "href": "prerequisite.html#minimum-system-requirements",
    "title": "Prerequisites",
    "section": "",
    "text": "WindowsmacOS\n\n\n\nOS: Windows 10/11\nMemory: &gt; 8 GB RAM\nROM: storage using Solid-state drive (SSD) is preferable. (Here‚Äôs how to check)\n\n\n\n\nOS: macOS 11 (Big Sur) or higher\nMemory: &gt; 8 GB RAM"
  },
  {
    "objectID": "prerequisite.html#software-requirements",
    "href": "prerequisite.html#software-requirements",
    "title": "Prerequisites",
    "section": "Software Requirements",
    "text": "Software Requirements\nBefore the workshop day, users are asked to install the following software in advance.\n\n1. Install R\nR is programming language for statistical computing and graphical visualization, and is an open-source software for computing in R language.\nUsers can download R installer from the Comprehensive R Archive Network (CRAN): https://cran.rstudio.com.\n\nThe latest R version is 4.3.0 (2023-04-21) -- \"Already Tomorrow\".\n\n\n\n2. Install Rtools (Windows users only)\nRtools is used to build and install R packages from source code. Some important tools, such as tidyverse, require Rtools to install on Windows.\nUsers can install Rtools from CRAN: https://cran.rstudio.com/bin/windows/Rtools/rtools43/files/rtools43-5550-5548.exe\n\nThe current Rtools for Windows users is Rtools 4.3, which is compatible with version R 4.3.x.\n\n\n\n3. Install Rstudio Desktop\nRstudio is an integrated development environment (IDE) for computing in R language. Users can install Rstudio Desktop from official posit website https://posit.co/download/rstudio-desktop.\n\nCurrent Rstudio Desktop version is Released: 2023-05-12.\n\n\n\n4. Install necessary R packages\nParticipants are required to install the following R packages from 2 sources, CRAN and Bioconductor, before the workshop day. All packages can be installed by copy and paste the following commands to RStudio console panel (in the bottom left panel of the RStudio screen), and hit the Enter key. Make sure your computer is already connected to the Internet.\n\n\n\nCopy and paste the installation commands to the console.\n\n\n4.1 Install packages from CRAN:\n\nif (!require(\"pacman\"))\n  install.packages(\"pacman\"\n  )\npacman::p_load(\n  tidyverse,\n  paletteer,\n  scales,\n  RColorBrewer,\n  ggpubr,\n  VennDiagram,\n  circlize,\n  viridis,\n  png,\n  GGally,\n  cowplot,\n  openxlsx,\n  gridExtra,\n  gtable,\n  egg,\n  ggfortify,\n  FactoMineR,\n  factoextra,\n  gridGraphics,\n  corrplot,\n  plotly,\n  agricolae,\n  ggsci\n)\n\n\n\n\nCopy and paste the installation commands to the console.\n\n\n4.2 Install packages from Bioconductor:\n\nif (!requireNamespace(\"BiocManager\", quietly = TRUE))\n  install.packages(\"BiocManager\")\n\nBiocManager::install(c(\"ComplexHeatmap\", \"DESeq2\", \n                       \"pcaExplorer\", \"EnhancedVolcano\"))\n\nüìß For technical issues regarding R packages installation, please email the issues to Prasert Yodsawat (prasert.y@outlook.com).\n\n\n\n\n\n\nOptional üìñ\n\n\n\nIn addition, users with some experience with R are beneficial. This workshop focuses on intermediate knowledge of R for managing and visualizing data. We recommend that participants familiarize themselves with the basics of R before attending this workshop. Here we also provide some online courses that would be helpful:\n\nR Programming Tutorial - Learn the Basics of Statistical Computing from freecodecamp.org\nIntroduction to R from Datacamp\nA (very) short introduction to R: The 10-page document by Torfs & Brauer with background information and exercises, plus 2 pages with a list of useful functions. Working through this document takes a couple of hours (depending on your background knowledge)."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "R Workshop 2023",
    "section": "",
    "text": "This workshop organized by Agricultural Biotech & Bioinformatics Lab, Division of Biological Science, on behalf of faculty of science, Prince of Songkla University, Hat Yai, Thailand.\n\nüìç Venue\nThe workshop will be at the room Bsc0303, Basic Science (BSc) Building (‡∏≠‡∏≤‡∏Ñ‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡πÅ‡∏•‡∏∞‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡∏ó‡∏≤‡∏á‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå)\n\n\n\n\n\n\n\n\nüìß Contact\nPlease contact us if you have any questions about this workshop. We are more than happy to help you. Our team is available to provide assistance and answer any queries you may have. Please don‚Äôt hesitate to reach out.\nTo get in touch on the course, please email to jirath.nuan@gmail.com, or you can get in touch directly to our supervisor at ponsit.sat@gmail.com.\nWe‚Äôre looking forward to see you !"
  },
  {
    "objectID": "lectures/basic_R.html#r-vs-rstudio-1",
    "href": "lectures/basic_R.html#r-vs-rstudio-1",
    "title": "Basic R Programming",
    "section": "R vs RStudio (1)",
    "text": "R vs RStudio (1)\n\n\n\n\n\n\n\n\nis a language and environment for statistical computing and graphics.\nProvides a wide variety of statistical (linear and nonlinear modelling, classical statistical tests, time-series analysis, classification, clustering, etc.) and publication-quality graphical techniques. And many more!\nFREE (under GNU-GPL license).\n\n\n\n\n\n\n\n\nRstudio is an integrated development environment (IDE) of R\nProvides extensible environments for compiling other languages (e.g.¬†Python, Shell, LaTeX, etc.) and engines (e.g.¬†knitr, Jupyter, quarto, etc.)\nFREE."
  },
  {
    "objectID": "lectures/basic_R.html#r-vs-rstudio-2",
    "href": "lectures/basic_R.html#r-vs-rstudio-2",
    "title": "Basic R Programming",
    "section": "R vs RStudio (2)",
    "text": "R vs RStudio (2)\n\n\n\n\n\nNormal R GUI\n\n\n\n\n\n\nRStudio user interface and its components"
  },
  {
    "objectID": "lectures/basic_R.html#r-versatility",
    "href": "lectures/basic_R.html#r-versatility",
    "title": "Basic R Programming",
    "section": "R: versatility",
    "text": "R: versatility"
  },
  {
    "objectID": "lectures/basic_R.html#loading-r-libraries-1",
    "href": "lectures/basic_R.html#loading-r-libraries-1",
    "title": "Basic R Programming",
    "section": "Loading R libraries (1)",
    "text": "Loading R libraries (1)\nCommon way to load library\n\nlibrary(tidyverse)"
  },
  {
    "objectID": "lectures/basic_R.html#loading-r-libraries-2",
    "href": "lectures/basic_R.html#loading-r-libraries-2",
    "title": "Basic R Programming",
    "section": "Loading R libraries (2)",
    "text": "Loading R libraries (2)\nMore efficient way to load multiple libraries at once with pacman:"
  },
  {
    "objectID": "lectures/basic_R.html#accessing-help-documentation-in-rstudio",
    "href": "lectures/basic_R.html#accessing-help-documentation-in-rstudio",
    "title": "Basic R Programming",
    "section": "Accessing Help & Documentation in RStudio",
    "text": "Accessing Help & Documentation in RStudio\n\n\nRStudio provides built-in documentation of all functions you have installed from libraries. For example, you would like to access documentation page of function aov, simply type in the console as follows:\n\nhelp(aov)\n# or \n?aov\n\nYou can access this documentation from the Help pane. The documentation includes an explanation of the arguments, background theorem, and references for the function aov.\n\n\n\n\n\n\nTip\n\n\nThere are 2 recommended repositories allow you to access all documentation online, RDocumentation.org and rdrr.io. These repositories contain all the documentation for all the functions available in R, even if you have never installed it!"
  },
  {
    "objectID": "lectures/basic_R.html#data-types",
    "href": "lectures/basic_R.html#data-types",
    "title": "Basic R Programming",
    "section": "Data types",
    "text": "Data types\nR has 5 data types:\n\n\n\nCharacter\n\n\na &lt;- c(\"May\", \"June\", \"July\")\nclass(a)\n\n[1] \"character\"\n\n\n\nNumeric\n\n\nb &lt;- c(-2.25, -1.5, 0, 1.0, 2.75, 3/4)\nclass(b)\n\n[1] \"numeric\"\n\n\n\nInteger\n\n\nc &lt;- as.integer(b)\nc\n\n[1] -2 -1  0  1  2  0\n\nclass(c)\n\n[1] \"integer\"\n\n\n\n\nLogical\n\nd &lt;- c(TRUE, FALSE, TRUE, FALSE)\nclass(d)\n\n[1] \"logical\"\n\n\nComplex\n\n\ne &lt;- 1+4i\nclass(e)\n\n[1] \"complex\"\n\n\n\n\n\n\n\n\nInfo\n\n\nR provides many functions to examine features of vectors and other objects, for example\n\nclass() - what kind of object is it?\nlength() - how long is it? What about two dimensional objects?"
  },
  {
    "objectID": "lectures/basic_R.html#data-structure-1",
    "href": "lectures/basic_R.html#data-structure-1",
    "title": "Basic R Programming",
    "section": "Data structure (1)",
    "text": "Data structure (1)\n\n\n\nVectors\nis a row of strings (can be numbers, characters, logicals , or mix of it), and also known as a 1-dimensional array. R uses function c to declare vectors:\n\nx &lt;- c(1, 4, 6, 8, 10)\n# Inspect vector\nx\n\n[1]  1  4  6  8 10\n\n# Access element in vector\nx[2]\n\n[1] 4\n\n# Calculating vector\nsum(x)\n\n[1] 29\n\n# Add another vector\ny &lt;- c(2, -2, 4, 9, 0.5)\ny\n\n[1]  2.0 -2.0  4.0  9.0  0.5\n\n# Calculating vector\nz &lt;- x + y\nz\n\n[1]  3.0  2.0 10.0 17.0 10.5\n\n\n\n\n\nMatrices\nis a 2-dimensional array, we use the function matrix to declare matrix in R as follow.\n\nmat &lt;- matrix(data = c(9, 2, 3, 4, 5, 6), nrow = 3)\n# Inspecting matrix\nmat\n\n     [,1] [,2]\n[1,]    9    4\n[2,]    2    5\n[3,]    3    6\n\n# Accessing element in 1st row, 2nd column of the matrix\nmat[1,2]\n\n[1] 4\n\n# Multiply matrix by 10\nmat*10\n\n     [,1] [,2]\n[1,]   90   40\n[2,]   20   50\n[3,]   30   60\n\n# Replace value in 3rd row, 1st column of the matrix to 20\nmat[3,1] &lt;- 20\nmat\n\n     [,1] [,2]\n[1,]    9    4\n[2,]    2    5\n[3,]   20    6"
  },
  {
    "objectID": "lectures/basic_R.html#data-structures-2",
    "href": "lectures/basic_R.html#data-structures-2",
    "title": "Basic R Programming",
    "section": "Data structures (2)",
    "text": "Data structures (2)\n\n\n\nData frames\nA data frame is a matrix in which rows and columns are named. A data frame is more flexible and compatible for further data manipulation and export as a spreadsheet. Also, data frame can be calculated like matrix.\n\n# Create a data frame\nt &lt;- data.frame(\n  name = c(\"gene1\", \"gene2\", \"gene3\", \"gene4\"),\n  cond_1 = c(20, 18, 0, 0),\n  cond_2 = c(1, 2, 100, 120)\n)\n# Access element in data frame\nt[4, 3]\n\n[1] 120\n\n# See how many rows and columns in the data frame\ndim(t)\n\n[1] 4 3\n\n# See what type of data format in each column\nstr(t)\n\n'data.frame':   4 obs. of  3 variables:\n $ name  : chr  \"gene1\" \"gene2\" \"gene3\" \"gene4\"\n $ cond_1: num  20 18 0 0\n $ cond_2: num  1 2 100 120\n\n\n\n\n\nLists\nList is a complex object that can store all data types and structures, even list within list!\n\nL1 &lt;- list(one = 1,\n           two = c(1, 2),\n           five = seq(0, 1, length = 5))\n# Inspect the list\nL1\n\n$one\n[1] 1\n\n$two\n[1] 1 2\n\n$five\n[1] 0.00 0.25 0.50 0.75 1.00\n\n# Access the 3rd structure in a list\nL1[3]\n\n$five\n[1] 0.00 0.25 0.50 0.75 1.00\n\n## Access the 2nd child element of the 3rd structure of the list\nL1[[3]][2]\n\n[1] 0.25\n\n# Calculating the list\nL1$five * 10\n\n[1]  0.0  2.5  5.0  7.5 10.0"
  },
  {
    "objectID": "lectures/basic_R.html#data-frames-1",
    "href": "lectures/basic_R.html#data-frames-1",
    "title": "Basic R Programming",
    "section": "Data frames (1)",
    "text": "Data frames (1)\nData frame is a key data structure in R and statistics.\n\nEach row represents observation (genes, protein, taxon, name)\nEach column represents variable (measures, treatments, characteristics) of the observation\nEach value in a cell represents each data point.\n\n\nStructure of data frame. Redraw from R for Data Science 2nd edition (Hadley Wickham & Garrett Grolemund)."
  },
  {
    "objectID": "lectures/basic_R.html#data-frames-2",
    "href": "lectures/basic_R.html#data-frames-2",
    "title": "Basic R Programming",
    "section": "Data frames (2)",
    "text": "Data frames (2)\nWe‚Äôll show structure of the data frames in 2 formats; wide and long formats, using airquality dataset.\n\n\nWide format\n\ndt_wide &lt;- datasets::airquality\n# Show how the data looks like\nhead(dt_wide)\n\n\n\n\n\n\nOzone\nSolar.R\nWind\nTemp\nMonth\nDay\n\n\n\n\n41\n190\n7.4\n67\n5\n1\n\n\n36\n118\n8.0\n72\n5\n2\n\n\n12\n149\n12.6\n74\n5\n3\n\n\n18\n313\n11.5\n62\n5\n4\n\n\nNA\nNA\n14.3\n56\n5\n5\n\n\n28\nNA\n14.9\n66\n5\n6\n\n\n\n\n\n\n\n\nHuman-readable data frame\nElegance\nEasy to see all values in each observation\nOne observation is one row\nMay incompatible for some plots in ggplot2\n\n\nLong format\n\ndt_long &lt;- datasets::airquality %&gt;%\n  pivot_longer(!c(Day, Month))\n# Show how the data looks like\nhead(dt_long)\n\n\n\n\n\n\nMonth\nDay\nname\nvalue\n\n\n\n\n5\n1\nOzone\n41.0\n\n\n5\n1\nSolar.R\n190.0\n\n\n5\n1\nWind\n7.4\n\n\n5\n1\nTemp\n67.0\n\n\n5\n2\nOzone\n36.0\n\n\n5\n2\nSolar.R\n118.0\n\n\n\n\n\n\n\n\nMachine-readable data frame\nSimple\nEach observation can be more than one row\nCompatible to include with metadata table (if any)\nggplot2 ‚ù§Ô∏èlong-format data frame"
  },
  {
    "objectID": "lectures/basic_R.html#managing-data-frames-with-dplyr",
    "href": "lectures/basic_R.html#managing-data-frames-with-dplyr",
    "title": "Basic R Programming",
    "section": "Managing data frames with dplyr",
    "text": "Managing data frames with dplyr\nWe can handle data frames with base R, but when you are working with a large data set, speed matters. The dplyr package provides a ‚Äúgrammar‚Äù (especially verbs) for data manipulation and for editing data frames.\nFrequently used dplyr verbs:\n\nglimpse: skim structure of the data, see every columns in a data frame.\nselect: return a subset of the columns of a data frame, using a flexible notation.\nfilter: extract a subset of rows from a data frame based on logical conditions.\narrange: reorder rows of a data frame.\nrename: rename variables in a data frame.\nmutate: add new variables/columns or transform existing variables.\nsummarise / summarize: generate summary statistics of different variables in the data frame, possibly within strata.\n%&gt;%: the ‚Äúpipe‚Äù operator, is used to connect multiple verb actions together into a pipeline."
  },
  {
    "objectID": "lectures/basic_R.html#common-dplyr-function-properties",
    "href": "lectures/basic_R.html#common-dplyr-function-properties",
    "title": "Basic R Programming",
    "section": "Common dplyr Function Properties",
    "text": "Common dplyr Function Properties\n\nThe first argument must be a data frame to process.\nThe subsequent arguments describe what to do with the data frame specified in the first argument, and you can refer to columns in the data frame directly without using the $ operator (just use the column names).\nThe return result of a function is a new data frame\n\nFor example:\n\n# Load dplyr library\nlibrary(dplyr)\n# Load airquality dataset\ndt &lt;- datasets::airquality\ndt_filtered &lt;- filter(dt, Solar.R &gt; 300)\n# Show how the data looks like\nhead(dt_filtered)\n\n  Ozone Solar.R Wind Temp Month Day\n1    18     313 11.5   62     5   4\n2    14     334 11.5   64     5  16\n3    34     307 12.0   66     5  17\n4    30     322 11.5   68     5  19\n5    11     320 16.6   73     5  22\n6    39     323 11.5   87     6  10"
  },
  {
    "objectID": "lectures/basic_R.html#dplyrglimpse",
    "href": "lectures/basic_R.html#dplyrglimpse",
    "title": "Basic R Programming",
    "section": "dplyr::glimpse",
    "text": "dplyr::glimpse\n\nCreate new variable dt_iris that stored the data set ‚Äúiris‚Äù.\n\n\n# Load dataset 'iris'\ndt_iris &lt;- datasets::iris\n\n\nGlimpse the data set in dt_iris\n\n\n# glimpse data\nglimpse(dt_iris)\n\n\nThree species of iris flowers in this data set: setosa, versicolor, and virginica. Figure from https://www.embedded-robotics.com/iris-dataset-classification."
  },
  {
    "objectID": "lectures/basic_R.html#dplyrselect",
    "href": "lectures/basic_R.html#dplyrselect",
    "title": "Basic R Programming",
    "section": "dplyr::select",
    "text": "dplyr::select\n\nWe already have data frame dt_iris from earlier practice. Now we will select columns name Species, and Petal.Width from dt and store in new variable: dt_sel\n\n\n# Select columns Petal.Width and Species from dt, keep in dt_sel\ndt_sel &lt;- select(dt_iris, Species, Petal.Width)\n\n\nThe glimpse the result.\n\n\n# Check the result by glimpse\nglimpse(dt_sel)"
  },
  {
    "objectID": "lectures/basic_R.html#dplyrfilter",
    "href": "lectures/basic_R.html#dplyrfilter",
    "title": "Basic R Programming",
    "section": "dplyr::filter",
    "text": "dplyr::filter\nfilter() is used to subset a data frame, retaining all rows that satisfy your conditions.\nFrom the data set iris stored in data frame dt_iris,\n\nNow we will filter Species ‚Äòversicolor‚Äô.\n\n\n# Filter versicolor species in dt_iris\ndt_versicolor &lt;- filter(dt_iris, Species == \"versicolor\")\n# Glimpse the result\nglimpse(dt_versicolor)\n\n\nFrom dt_versicolor, filter the flowers that the Sepal.Length longer than or equal to 6\n\n\n# Filter the versicolor iris that the sepal length longer than or equal to 6\ndt_vsc_filt &lt;- filter(dt_versicolor, Sepal.Length &gt;= 6)\n\n\nThen glimpse the result\n\n\n# Glimpse the result\nglimpse(dt_vsc_filt)"
  },
  {
    "objectID": "lectures/basic_R.html#dplyrarrange",
    "href": "lectures/basic_R.html#dplyrarrange",
    "title": "Basic R Programming",
    "section": "dplyr::arrange",
    "text": "dplyr::arrange\narrange() orders the rows of a data frame by the values of selected columns.\n\nIn our filtered data frame dt_vsc_filt, sort the Sepal.Length column.\n\n\n# Sort data frame dt_vsc_filt by sepal length column (ascendingly)\ndt_vsc_filt_srt &lt;- arrange(dt_vsc_filt, Sepal.Length)\n\n\nThen, sort the Petal.Length descendingly.\n\n\n# Sort data frame dt_vsc_filt descendingly by petal length column\ndt_vsc_filt_srt &lt;- arrange(dt_vsc_filt, desc(Petal.Length))\n\n\nGlimpse the result\n\n\nglimpse(dt_vsc_filt_srt)"
  },
  {
    "objectID": "lectures/basic_R.html#dplyrrename",
    "href": "lectures/basic_R.html#dplyrrename",
    "title": "Basic R Programming",
    "section": "dplyr::rename",
    "text": "dplyr::rename\nrename() changes the names of individual variables using new_name = old_name syntax.\n\nFrom sorted and filtered data frame dt_vsc_filt_srt, we will rename 2 columns, from Sepal.Length and Petal.Length, to SL and PL, respectively. Then save to the new data frame dt_vsc_renamed.\n\n\n# Rename column from Sepal.Length to SL, and Petal.Length to PL, then save to the new data frame dt_vsc_renamed\ndt_vsc_renamed &lt;- rename(dt_vsc_filt_srt, \n                         SL = Sepal.Length,\n                         PL = Petal.Length)"
  },
  {
    "objectID": "lectures/basic_R.html#dplyrmutate",
    "href": "lectures/basic_R.html#dplyrmutate",
    "title": "Basic R Programming",
    "section": "dplyr::mutate",
    "text": "dplyr::mutate\nmutate() creates new columns that are functions of existing variables, as well as modify and delete columns.\n\nFrom the previous data frame dt_vsc_renamed, we‚Äôll calculate the difference between sepal length SL and petal length PL to the new column Len_Diff. This can be done with the mutate() function as follow.\n\n\n# Calculate difference of sepal length and petal length, add to the new column Len_Diff\ndt_vsc_renamed &lt;- mutate(dt_vsc_renamed,\n                         Len_Diff = SL - PL)\n\n\nThen, use function summary() to see the distribution of the values using the column Len_Diff.\n\n\n# Rough summarize the difference of sepal length and petal length \nsummary(dt_vsc_renamed$Len_Diff)\n\nExpected result:\n\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n    0.9     1.5     1.9     1.8     2.0     2.3"
  },
  {
    "objectID": "lectures/basic_R.html#dplyr",
    "href": "lectures/basic_R.html#dplyr",
    "title": "Basic R Programming",
    "section": "dplyr::%>%",
    "text": "dplyr::%&gt;%\nThe pipeline operator %&gt;% (pronounce: pipe) is very handy for bundling dplyr verbs and creating complex syntax for processing data. For example:\n\nInstead of using dplyr verbs and storing the new variables line by line, we can bundle them and use %&gt;%. All operations associated with %&gt;% are stored in one variable.\n\n\niris_df &lt;- datasets::iris %&gt;% \n  rename(SL = Sepal.Length,\n         SW = Sepal.Width,\n         PL = Petal.Length,\n         PW = Petal.Width) %&gt;% \n  mutate(Len_Diff = SL - PL) %&gt;% \n  filter(Len_Diff &gt; 1)\n\nFrom the syntax above:\n\nWe loaded the iris data set to the variable iris_df.\nThen rename the column name with rename() function.\nThen calculate the difference of sepal length and petal length using mutate() function.\nAnd keep the difference that are greater than 1 using filter() function.\nAll of these verbs are operated and store in one variable, iris_df."
  },
  {
    "objectID": "lectures/basic_R.html#dplyrsummarize",
    "href": "lectures/basic_R.html#dplyrsummarize",
    "title": "Basic R Programming",
    "section": "dplyr::summarize",
    "text": "dplyr::summarize\nsummarise() returns one row for each combination of grouping variables. It will contain one column for each grouping variable and one column for each of the summary statistics that you have specified.\n\nWe‚Äôll load original datasets::iris to the new data frame dt2_iris.\n\n\n# Load iris dataset\ndt2_iris &lt;- datasets::iris\n# glimpse data\nglimpse(dt2_iris)\n\n\nOf these 3 species, calculate mean and standard deviation of petal length using mean() and sd(), respectively. Then calculate the standard deviation of mean (SEM) of the petal length.\n\n\\[\nSEM = \\frac{SD}{\\sqrt{n}}\n\\]\n\n\n\ndt2_iris &lt;- datasets::iris %&gt;%\n  group_by(Species) %&gt;%\n  summarise(\n    num_flowers = n(),\n    Mean_PL = mean(Petal.Length),\n    SD_PL = sd(Petal.Length)) %&gt;% \n  mutate(SEM_PL = SD_PL/sqrt(num_flowers))\n\n\n\n\n\n\n\nSpecies\nnum_flowers\nMean_PL\nSD_PL\nSEM_PL\n\n\n\n\nsetosa\n50\n1.462\n0.1736640\n0.0245598\n\n\nversicolor\n50\n4.260\n0.4699110\n0.0664554\n\n\nvirginica\n50\n5.552\n0.5518947\n0.0780497"
  },
  {
    "objectID": "lectures/basic_R.html#plotting-systems-in-r",
    "href": "lectures/basic_R.html#plotting-systems-in-r",
    "title": "Basic R Programming",
    "section": "Plotting systems in R",
    "text": "Plotting systems in R\nPlotting is an important tool for understanding data properties, finding patterns in the data, suggesting modeling strategies for our data, and communicating what we have found in our data. Many plotting systems available in R such as:\n\nBase graphic conventional way, same as implementing graphical visualizations in the S language. You can only draw on the plot, and append another plot to it.\nGrid graphic or Grobs (graphical objects), not used to create statistical graphs per se, but are insanely useful in combining and laying out multiple graphic devices.\nLattice Plots uses lattice graphics to implement the Trellis graphics system. Also known as an improved version of Base Plot.\nggplot2 improves base and lattice graphics. The graphics are drawn using grids, which allows you to manipulate their appearance at many levels.\nhtmlwidgets provides a common framework for accessing web visualization tools from R. Userful for creating interactive plots for publishing on websites.\nplotly is a popular javascript visualization toolkit with an R interface. It is a great tool if you want to create interactive graphics for HTML documents or websites.\n\nAnother graphic systems, ComplexHeatmap (Gu 2022), will be used in this workshop as well."
  },
  {
    "objectID": "lectures/basic_R.html#base-graphics-1",
    "href": "lectures/basic_R.html#base-graphics-1",
    "title": "Basic R Programming",
    "section": "Base graphics (1)",
    "text": "Base graphics (1)\nUsing library graphics, plain and simple plot functions in R is usually called R base plot. The syntax is shown as follow:\n\n\n\nplot(rnorm(100), type = \"p\", col = \"red\")\n\n\n\n\nThis is a scatter plot showing 100 random numbers. Each red point indicates a data point.\n\n\nhist(rnorm(100))\n\n\n\n\nAnother simple plot to show the pattern of the data is histogram."
  },
  {
    "objectID": "lectures/basic_R.html#base-graphics-2",
    "href": "lectures/basic_R.html#base-graphics-2",
    "title": "Basic R Programming",
    "section": "Base graphics (2)",
    "text": "Base graphics (2)\nThe following lines create a plot from data frame t.\n\n# Creating a data frame\nt &lt;- data.frame(x = c(11,12,14), \n                y = c(19,20,21), \n                z = c(10,9,7))\n# Creating a new plot\nplot(t$x, type = \"b\", ylim = range(t), col = \"red\")\n# Adding new graphic to the plot\nlines(t$y, type = \"s\", col = \"blue\")\n# Adding another graphic to the plot\npoints(t$z, pch = 20, cex = 2, col = \"green\")"
  },
  {
    "objectID": "lectures/basic_R.html#lattice-graphic",
    "href": "lectures/basic_R.html#lattice-graphic",
    "title": "Basic R Programming",
    "section": "Lattice graphic",
    "text": "Lattice graphic\nAttempts to improve R‚Äôs basic graphs by providing better presets and the ability to display multivariate relationships. In particular, the package supports the creation of grid graphs - graphs that show a variable or the relationship between variables as a function of one or more other variables.\n\n\n\n# Load package\nlibrary(lattice)\n\n# Load Toothgrowth data set\nToothGrowth &lt;- datasets::ToothGrowth\n# Density plot\ndensityplot(~ len, groups = dose, data = ToothGrowth,\n            plot.points = FALSE, auto.key = TRUE)\n\n\n\n\n\n\n# Load iris data set\ndt &lt;- datasets::iris\n# Plot scatter plot\nxyplot(Sepal.Length ~ Petal.Length | Species,\n       group = Species,\n       data = dt,\n       type = c(\"p\", \"smooth\"),\n       scales = \"free\")"
  },
  {
    "objectID": "lectures/basic_R.html#ggplot2",
    "href": "lectures/basic_R.html#ggplot2",
    "title": "Basic R Programming",
    "section": "ggplot2",
    "text": "ggplot2\nThe ggplot2 package is an R package for creating graphs or plots of statistical data. With ggplot2, you can compose graphs by combining independent components based on the Grammar of Graphics.\n\n\n\n# Load package\nlibrary(ggplot2)\n# create scatterplot of carat vs. price, \n# using cut as color variable\nggplot(data = diamonds, \n       aes(x = carat, y = price, color = cut)) +\n  geom_point()\n\n\n\n\n\n\n# Create scatterplot of price, grouped by cut\nggplot(data = diamonds, \n       aes(x = cut, y = price)) + \n  geom_boxplot(fill = \"firebrick\") +\n  theme_bw()\n\n\n\n\n\n\nWe‚Äôll mainly use ggplot2 and other graphic libraries in this workshop üôÇ"
  },
  {
    "objectID": "lectures/basic_R.html#tidyverse",
    "href": "lectures/basic_R.html#tidyverse",
    "title": "Basic R Programming",
    "section": "Tidyverse",
    "text": "Tidyverse\n\n\nTidyverse is a collection of R packages for data science. All Tidyverse packages share the same design philosophy, grammar, and data structures. The core of Tidyverse includes packages that you will use in your daily data analysis.\n¬†\n\n# Load tidyverse\nlibrary(tidyverse)\n\n\n\n\n\nCore packages in Tidyverse."
  },
  {
    "objectID": "lectures/basic_R.html#references",
    "href": "lectures/basic_R.html#references",
    "title": "Basic R Programming",
    "section": "References",
    "text": "References\n\nA (very) short introduction to R: written by Torfs & Brauer, Hydrology and Quantitative Water Management Group, Wageningen University.\nWorkshop on Data Visualization in R: by National Bioinformatics Infrastructure Sweden (NBIS), on behalf of SciLifeLab.\nR for Data Science (2nd Edition): written by Hadley Wickham, Mine √áetinkaya-Rundel, and Garrett Grolemund.\nExploratory Data Analysis with R: written by Roger D. Peng, Johns Hopkins Bloomberg School of Public Health. 2020\nggplot2: Elegant Graphics for Data Analysis (3e): written by Hadley Wickham, Danielle Navarro, and Thomas Lin Pedersen (2023).\n\n\n\n\n17 May 2023\n\n\n\nGu, Zuguang. 2022. ‚ÄúComplex Heatmap Visualization.‚Äù iMeta 1 (3). https://doi.org/10.1002/imt2.43."
  },
  {
    "objectID": "lectures/exploratory_data_analysis.html#eda-why",
    "href": "lectures/exploratory_data_analysis.html#eda-why",
    "title": "Exploratory Data Analysis",
    "section": "EDA: Why?",
    "text": "EDA: Why?\nExploratory Data Analysis (EDA) is the way to observe your data, and can be an iterative cycle since you have cleaned the data. Generally, as of Wickham, √áetinkaya-Rundel, and Grolemund (2023), aims of EDA are:\n\nGenerate questions about your data\nSearch for answers by visualizing, transforming, and modelling your data\nUse what you learn to refine your questions and/or generate new questions.\nThis is important even if you already have research questions in mind.\nTo choose the suitable means for data cleaning."
  },
  {
    "objectID": "lectures/exploratory_data_analysis.html#simple-steps-for-eda-in-r",
    "href": "lectures/exploratory_data_analysis.html#simple-steps-for-eda-in-r",
    "title": "Exploratory Data Analysis",
    "section": "10 Simple Steps for EDA in R",
    "text": "10 Simple Steps for EDA in R\nReferred from Peng (2020), here‚Äôs a quick steps to do for exploratory data analysis in R.\n\nFormulate your question\nRead in your data\nCheck the packaging\nGlimpse\nLook at the top and the bottom of the data\nCheck for the n\nValidate with at least one external data source\nTry the easy solution first\nChallenge your solution\nFollow up"
  },
  {
    "objectID": "lectures/exploratory_data_analysis.html#activity",
    "href": "lectures/exploratory_data_analysis.html#activity",
    "title": "Exploratory Data Analysis",
    "section": "Activity",
    "text": "Activity\nFor today‚Äôs EDA exercise, we will examine mortality rates by infectious and parasitic diseases. The data is adopted from the World Health Organization WHO Mortality Database. The data was collected from 1950 to 2021 in many countries around the world."
  },
  {
    "objectID": "lectures/exploratory_data_analysis.html#step-1-formulate-your-question",
    "href": "lectures/exploratory_data_analysis.html#step-1-formulate-your-question",
    "title": "Exploratory Data Analysis",
    "section": "Step 1: Formulate your question",
    "text": "Step 1: Formulate your question\nA good and sharp question or hypothesis could lead to clearing up more possible ways to answer the questions in the EDA process.\n¬†\n‚ùìCan you formulate the questions that you attempt to find the answer from this data?\n¬†\n\n\n\nTip\n\n\nThe most important questions you can answer with the EDA process is ‚ÄúDo I have the right data to answer this question?‚Äù. Though the question is difficult to answer at the beginning, the it is a good start to do EDA!"
  },
  {
    "objectID": "lectures/exploratory_data_analysis.html#step-2-load-your-data",
    "href": "lectures/exploratory_data_analysis.html#step-2-load-your-data",
    "title": "Exploratory Data Analysis",
    "section": "Step 2: Load your data",
    "text": "Step 2: Load your data\nNow we will load the data set in CSV format into R environment using read_csv() function as follows.\n¬†\n\n# Load libraries\nlibrary(tidyverse)\n# Retrieve data set\nmortality_rate &lt;- read_csv(file = \"https://raw.githubusercontent.com/JirathNuan/r-handviz-workshop/main/datasets/WHOMortalityDatabase_Infectious-and-parasitic-diseases_2023-05-03.csv\", comment = \"#\")\n\n¬†\nWhat we may have found:\n\nWas the data frame object loaded mortality_rate correctly ?\nAre there any errors/warnings during loading ?\nFrom Rstudio, how many objects and variables in data set observed from environment panel ?"
  },
  {
    "objectID": "lectures/exploratory_data_analysis.html#step-3-check-the-data-dimension",
    "href": "lectures/exploratory_data_analysis.html#step-3-check-the-data-dimension",
    "title": "Exploratory Data Analysis",
    "section": "Step 3: Check the data dimension",
    "text": "Step 3: Check the data dimension\n\nWe can check the number of rows and columns of the data frame using dim() as follows.\n\n\n# See how many rows and columns in the data\ndim(mortality_rate)\n\n¬†\nThen see the column names with colnames()\n\n# see column names\ncolnames(mortality_rate)"
  },
  {
    "objectID": "lectures/exploratory_data_analysis.html#step-4-glimpse-the-data",
    "href": "lectures/exploratory_data_analysis.html#step-4-glimpse-the-data",
    "title": "Exploratory Data Analysis",
    "section": "Step 4: Glimpse the data",
    "text": "Step 4: Glimpse the data\nAs mentioned in the R Basic Programming lecture, we can use the glimpse() function to see each column in the data frame as well as the column types and some values in that column as follow.\n¬†\n\n# Glimpse data frame\nglimpse(mortality_rate)\n\n¬†\nAs we can see from the output, glimpse() can show how many rows and columns there are, just like the dim() function. In addition, glimpse() also examine the class of each column to make sure they are specified correctly during loading."
  },
  {
    "objectID": "lectures/exploratory_data_analysis.html#step-5-look-at-the-top-and-the-bottom-of-the-data",
    "href": "lectures/exploratory_data_analysis.html#step-5-look-at-the-top-and-the-bottom-of-the-data",
    "title": "Exploratory Data Analysis",
    "section": "Step 5: Look at the top and the bottom of the data",
    "text": "Step 5: Look at the top and the bottom of the data\nOther useful functions to look at the beginning and end of the data frame are head() and tail() functions, respectively.\n¬†\n\n# Show the first 10 lines of the data frame\nhead(mortality_rate, n = 10)\n# Show the last 10 lines of the data frame\ntail(mortality_rate, n = 10)\n\n¬†\nWith these functions:\n\nWe can determine if the data was loaded correctly or not.\nWere the column names defined correctly?\nWere there no column names at all in the beginning ?\nWas the data loaded completely from the first to the last line of the file ?"
  },
  {
    "objectID": "lectures/exploratory_data_analysis.html#step-6-check-for-the-n",
    "href": "lectures/exploratory_data_analysis.html#step-6-check-for-the-n",
    "title": "Exploratory Data Analysis",
    "section": "Step 6: Check for the n",
    "text": "Step 6: Check for the n\n\nThis step is counting what you want to examine their number (n).\nIn general, counting things is a good way to find out if something is going wrong after you load the data. Whether or not duplicate values or NA are observed.\n\n\n# Counting number of countries in the data set\ncount_countries &lt;- length(unique(mortality_rate$country_name))\ncount_countries\n\n# For each country, how many data points \ntbl_countries &lt;- table(mortality_rate$country_name)\ntbl_countries\n\n# How many countries in Asia \nmortality_rate %&gt;% \n  filter(region_name == \"Asia\") %&gt;% \n  distinct(country_name) %&gt;% \n  count()\n\n# From 2000 to 2021, how many countries in Asia, where the mortality rate is available in these years. \nmortality_rate %&gt;% \n  filter(region_name == \"Asia\" &\n           year &gt;= 2000 & \n           year &lt;= 2021) %&gt;% \n  group_by(year) %&gt;% \n  count()\n\n# From the above examination, we can see in which year the mortality rate is the highest by adding arrange()\nmortality_rate %&gt;% \n  filter(region_name == \"Asia\" &\n           year &gt;= 2000 & \n           year &lt;= 2021) %&gt;% \n  group_by(year) %&gt;% \n  count() %&gt;% \n  arrange(desc(n))"
  },
  {
    "objectID": "lectures/exploratory_data_analysis.html#step-7-validate-with-at-least-one-external-data-source",
    "href": "lectures/exploratory_data_analysis.html#step-7-validate-with-at-least-one-external-data-source",
    "title": "Exploratory Data Analysis",
    "section": "Step 7: Validate with at least one external data source",
    "text": "Step 7: Validate with at least one external data source\n\nIt is very important to make sure that your data matches something outside the data set. For example, you can cross-check with mortality database from health agencies in the desired countries. This way you can make sure that the measurements are about what they should be, and it serves as a check to see what other things in your data set might be wrong.\nBased on our data, we can easily check the distribution of values with many functions, such as quantile() and summary() as follow.\n\n\n# Summarize the distribution of death rate per 100,000 populations\nsummary(mortality_rate$death_rate_per_100k)\n# Distribute to quantile rank\nquantile(mortality_rate$death_rate_per_100k, na.rm = TRUE)\n\n\nWith summary(), you can even summarize every columns in the data frame at once as follow.\n\n\n# Summarize data frame\nsummary(mortality_rate)"
  },
  {
    "objectID": "lectures/exploratory_data_analysis.html#step-8-try-the-easy-solution-first",
    "href": "lectures/exploratory_data_analysis.html#step-8-try-the-easy-solution-first",
    "title": "Exploratory Data Analysis",
    "section": "Step 8: Try the easy solution first",
    "text": "Step 8: Try the easy solution first\n\nSuppose the question we want to answer is\n\n\nSince the data collected from 1950 - 2021, which region contains the highest number of deaths ?\n\nTo answer the question, we need to group the data by region and examine what the region has the highest number of deaths.\n\n# Examining the number of deaths by region\nmortality_rate %&gt;% \n  filter(!is.na(number)) %&gt;% \n  group_by(region_name) %&gt;% \n  summarise(total_death_per_region = sum(number)) %&gt;% \n  ggplot(aes(x = region_name, y = total_death_per_region)) +\n  geom_col()\n\n\nIs it different number of death between sex in each region ?\n\n\n# Examine the number of deaths by region and sex\nmortality_rate %&gt;%\n  filter(!is.na(number)) %&gt;% \n  group_by(region_name, sex) %&gt;%\n  summarise(total_death_per_region = sum(number)) %&gt;% \n  ggplot(aes(x = region_name, y = total_death_per_region, fill = sex)) +\n  geom_col(position = position_dodge(0.9, preserve = \"single\"))"
  },
  {
    "objectID": "lectures/exploratory_data_analysis.html#step-9-challenge-your-solution",
    "href": "lectures/exploratory_data_analysis.html#step-9-challenge-your-solution",
    "title": "Exploratory Data Analysis",
    "section": "Step 9: Challenge your solution",
    "text": "Step 9: Challenge your solution\n\nTrying easy solution is good, because it fast and easy to answer the questions. But it is always better idea to challenge the results, especially if they fit with your expectations.\nEven if our simple solutions work well, but surely there are some obstacles challenge you to treat it. For example\n\nWas the data collected every year in each countries ?\nWith the past solution, how can we handle NA, or data with unknown sex ? Should it be excluded?\nDo you observe any unusual values in your data? Why did this happen?\n\n\nWe will show an example to examine the unusual values (outliers) of number of deaths.\n\n# Examining overall number of deaths by region in 10 years backward (2012 - 2021)\nmortality_rate %&gt;% \n  filter(year &gt;= 2012) %&gt;% \n  ggplot(aes(x = as.character(year), \n             y = number)) +\n  geom_boxplot() +\n  facet_wrap(. ~ region_name, scales = \"free_y\")\n\n¬†\n‚ùìAre there any unusual values in the box plot ? If so, how can we examine them more closely ?"
  },
  {
    "objectID": "lectures/exploratory_data_analysis.html#step-10-follow-up-questions",
    "href": "lectures/exploratory_data_analysis.html#step-10-follow-up-questions",
    "title": "Exploratory Data Analysis",
    "section": "Step 10: Follow up questions",
    "text": "Step 10: Follow up questions\nWe are able to formulate questions in our data and try to solve the problems in a simple and challenging way.\n¬†\nAt this point, it makes sense to ask a few follow-up questions:\n\nDo you have the right data?\nDo you need other data?\nDo you have the right question?\n\n¬†\nExploratory data analysis is designed to get you thinking about your data and your question. At this point, we can refine our question or collect relevant data, over and over to get to the truth."
  },
  {
    "objectID": "lectures/exploratory_data_analysis.html#wicked-fast-and-convenient-eda-package-ggally",
    "href": "lectures/exploratory_data_analysis.html#wicked-fast-and-convenient-eda-package-ggally",
    "title": "Exploratory Data Analysis",
    "section": "Wicked fast and convenient EDA package: GGally",
    "text": "Wicked fast and convenient EDA package: GGally\nWe can use the ggpairs() function from the GGally package1 (pronounced: g-g-ally) to get a general overview of our data. Instead of plotting relationship variables pair by pair in one plot, with ggpairs(), we can explore initial relationships or each variable in more detail.\n\n# Load GGally package \n# We asked the participants to install before the workshop\nlibrary(GGally)\n# remove some columns and tidy data\nmortality_rate_2 &lt;- mortality_rate %&gt;% \n  select(-c(country_name, age_std_death_rate_per_100k,\n            age_group, number)) %&gt;% \n  filter(year &gt;= 2012)\nmortality_rate_2$year &lt;- as.character(mortality_rate_2$year)\n# Explore relationship in our data, colored by region name\np_mortality_overview &lt;- ggpairs(mortality_rate_2, \n                                aes(colour = region_name),\n                                progress = TRUE,\n                                cardinality_threshold = 20)\n# Export plot to file\nggsave(\"mortality_rate_overview.png\", p_mortality_overview,\n       width = 20, height = 10, units = \"in\", dpi = 300, scale = 0.8)\n\nGGally: Extension to ggplot2 (https://ggobi.github.io/ggally)"
  },
  {
    "objectID": "lectures/exploratory_data_analysis.html#practice",
    "href": "lectures/exploratory_data_analysis.html#practice",
    "title": "Exploratory Data Analysis",
    "section": "Practice",
    "text": "Practice\nWe‚Äôll perform the EDA approach to initially explore the characteristics of the data set from Ghazalpour et al. (2006). The data set describes several physiological quantitative traits of female mice of a specific F2 intercross.\nFirst load the data into R environment:\n\nliverMice &lt;- read_csv(\"https://github.com/JirathNuan/r-handviz-workshop/raw/main/datasets/mouseLiver_data_ClinicalTraits.csv\")\n\nüìì First, let‚Äôs try to explore overall aspects of the data using ggpairs() from GGally library. Are there any interesting variables to dig deeper ?\nüìì Given the data set, what type of visualization would be appropriate. And why ?"
  },
  {
    "objectID": "lectures/exploratory_data_analysis.html#references",
    "href": "lectures/exploratory_data_analysis.html#references",
    "title": "Exploratory Data Analysis",
    "section": "References",
    "text": "References\n\n\nGhazalpour, Anatole, Sudheer Doss, Bin Zhang, Susanna Wang, Christopher Plaisier, Ruth Castellanos, Alec Brozell, et al. 2006. ‚ÄúIntegrating Genetic and Network Analysis to Characterize Genes Related to Mouse Weight.‚Äù Edited by Greg Gibson. PLoS Genetics 2 (8): e130. https://doi.org/10.1371/journal.pgen.0020130.\n\n\nPeng, Roger D. 2020. Exploratory Data Analysis with r. https://bookdown.org/rdpeng/exdata/.\n\n\nWickham, Hadley, Mine √áetinkaya-Rundel, and Garrett Grolemund. 2023. R for Data Science. 2nd ed. https://r4ds.hadley.nz/.\n\n\n\n\n\n17 May 2023"
  },
  {
    "objectID": "lectures/grammar_of_graphics.html#what-is-grammar-of-graphics",
    "href": "lectures/grammar_of_graphics.html#what-is-grammar-of-graphics",
    "title": "Grammar of Graphics",
    "section": "What is Grammar of Graphics",
    "text": "What is Grammar of Graphics\n\n\n\n\n\n\n\n\n¬†\n\nData: Your input data (in long format)\nAesthetics: what makes your data visible, e.g., size, line color, variables to plot, fill color, line type, transparency, etc.\nGeometry: determines the type of plot.\nStatistics: statistical transformation of continuous data\nFacets: for splitting plot into subplots.\nCoordinates: Numeric systems to limit, breakdown, transform position of geometry.\nThemes: Overall visual of plots and customization."
  },
  {
    "objectID": "lectures/grammar_of_graphics.html#building-a-plot-layer-by-layer",
    "href": "lectures/grammar_of_graphics.html#building-a-plot-layer-by-layer",
    "title": "Grammar of Graphics",
    "section": "Building a plot layer-by-layer",
    "text": "Building a plot layer-by-layer\n\nLoad data with ggplot()\n\n\n# Load library\nlibrary(ggplot2)\n# Define data and global aesthetics\nggplot(diamonds)"
  },
  {
    "objectID": "lectures/grammar_of_graphics.html#building-a-plot-layer-by-layer-1",
    "href": "lectures/grammar_of_graphics.html#building-a-plot-layer-by-layer-1",
    "title": "Grammar of Graphics",
    "section": "Building a plot layer-by-layer",
    "text": "Building a plot layer-by-layer\n\nAdd aesthetics by aes()\n\n\n# Load library\nlibrary(ggplot2)\n# Plot diamonds\nggplot(diamonds, aes(x = carat, y = price, color = cut))"
  },
  {
    "objectID": "lectures/grammar_of_graphics.html#building-a-plot-layer-by-layer-2",
    "href": "lectures/grammar_of_graphics.html#building-a-plot-layer-by-layer-2",
    "title": "Grammar of Graphics",
    "section": "Building a plot layer-by-layer",
    "text": "Building a plot layer-by-layer\n\nAdd geometry by geom()\n\n\n# Load library\nlibrary(ggplot2)\n# Define data and global aesthetics\nggplot(diamonds, aes(x = carat, y = price, color = color)) +\n  geom_point(alpha = 0.8)"
  },
  {
    "objectID": "lectures/grammar_of_graphics.html#building-a-plot-layer-by-layer-3",
    "href": "lectures/grammar_of_graphics.html#building-a-plot-layer-by-layer-3",
    "title": "Grammar of Graphics",
    "section": "Building a plot layer-by-layer",
    "text": "Building a plot layer-by-layer\n\nAdd statistics\n\n\n# Load library\nlibrary(ggplot2)\n# Define data and global aesthetics\nggplot(diamonds, aes(x = carat, y = price, color = color)) +\n  geom_point(alpha = 0.8) +\n  stat_smooth(color = \"black\", linewidth = 0.8)"
  },
  {
    "objectID": "lectures/grammar_of_graphics.html#building-a-plot-layer-by-layer-4",
    "href": "lectures/grammar_of_graphics.html#building-a-plot-layer-by-layer-4",
    "title": "Grammar of Graphics",
    "section": "Building a plot layer-by-layer",
    "text": "Building a plot layer-by-layer\n\nAdd facets\n\n\n# Load library\nlibrary(ggplot2)\n# Define data and global aesthetics\nggplot(diamonds, aes(x = carat, y = price, color = color)) +\n  geom_point(alpha = 0.8) +\n  stat_smooth(color = \"black\", linewidth = 0.8) +\n  facet_grid(cut ~ color)"
  },
  {
    "objectID": "lectures/grammar_of_graphics.html#building-a-plot-layer-by-layer-5",
    "href": "lectures/grammar_of_graphics.html#building-a-plot-layer-by-layer-5",
    "title": "Grammar of Graphics",
    "section": "Building a plot layer-by-layer",
    "text": "Building a plot layer-by-layer\n\nAdding coordinates\n\n\n# Load library\nlibrary(ggplot2)\n# Define data and global aesthetics\nggplot(diamonds, aes(x = carat, y = price, color = color)) +\n  geom_point(alpha = 0.8) +\n  stat_smooth(color = \"black\", linewidth = 0.8) +\n  facet_grid(cut ~ color) +\n  scale_y_continuous(breaks = seq(from = 0, to = 20000, by = 10000))"
  },
  {
    "objectID": "lectures/grammar_of_graphics.html#building-a-plot-layer-by-layer-6",
    "href": "lectures/grammar_of_graphics.html#building-a-plot-layer-by-layer-6",
    "title": "Grammar of Graphics",
    "section": "Building a plot layer-by-layer",
    "text": "Building a plot layer-by-layer\n\nAdding theme\n\n\n# Load library\nlibrary(ggplot2)\n# Define data and global aesthetics\nggplot(diamonds, aes(x = carat, y = price, color = color)) +\n  geom_point(alpha = 0.8) +\n  stat_smooth(color = \"black\", linewidth = 0.8) +\n  facet_grid(cut ~ color) +\n  scale_y_continuous(breaks = seq(from = 0, to = 20000, by = 10000)) +\n  theme_bw()"
  },
  {
    "objectID": "lectures/grammar_of_graphics.html#aesthetics",
    "href": "lectures/grammar_of_graphics.html#aesthetics",
    "title": "Grammar of Graphics",
    "section": "Aesthetics",
    "text": "Aesthetics\n\nAesthetics aes() describe how variables map to visual properties or aesthetics.\nThe position of data points are described by values from x and y\nshape, size, or color styles can also be specified in aes().\n\n\nCommonly used aesthetics in data visualization: position, shape, size, color, line width, line type. Figure from Wilke (2019)"
  },
  {
    "objectID": "lectures/grammar_of_graphics.html#types-of-variables-used-in-aesthetics",
    "href": "lectures/grammar_of_graphics.html#types-of-variables-used-in-aesthetics",
    "title": "Grammar of Graphics",
    "section": "Types of Variables Used in Aesthetics",
    "text": "Types of Variables Used in Aesthetics\n\n\nContinuous variables\n\nA variable or a set of value you can measure.\nContinuous data values are values you can arbitrarily fine intermediates.\nAge, height, BMI, date, assignment score, etc.\nSometimes, series of continuous variable can be a discrete variable.\n\n\nmy_seq &lt;- seq(from = 0, to = 10, by = 1)\nclass(my_seq)\nsum(my_seq)\ncount(my_seq)\n\nmy_seq2 &lt;- as.character(my_seq)\nclass(my_seq2)\nsum(my_seq2)\ncount(my_seq2)\n\n\nDiscrete variables\n\nA variable or a set of value you can count.\nGrade (A B C D), Name, Type, number of person in a room, etc.\nSometimes a vector of a discrete variable can be classified into a kind of ordinal number. That may required before time-series plotting.\n\n\nmy_var &lt;- c(\"0_hpi\", \"12hpi\", \"Control\", \"48_hpi\", \"24_hpi\")\nmy_var\n\nmy_var_2 &lt;- factor(my_var, \n                   levels = c(\"Control\", \"0_hpi\", \"12hpi\",\n                              \"24_hpi\", \"48_hpi\"))\nmy_var_2"
  },
  {
    "objectID": "lectures/grammar_of_graphics.html#geoms",
    "href": "lectures/grammar_of_graphics.html#geoms",
    "title": "Grammar of Graphics",
    "section": "Geoms",
    "text": "Geoms\nFrequently used geoms (Explore more plot in R Graph Gallery: https://r-graph-gallery.com)\n\n\n\n\n\n\nFigure¬†1: geom_histogram()\n\n\n\n\n\n\n\nFigure¬†2: geom_bar()\n\n\n\n\n\n\n\nFigure¬†3: geom_line() with geom_point()\n\n\n\n\n\n\n\nFigure¬†4: geom_boxplot() with geom_jitter()\n\n\n\n\n\n\n\n\n\nFigure¬†5: geom_violin()\n\n\n\n\n\n\n\nFigure¬†6: geom_density()\n\n\n\n\n\n\n\nFigure¬†7: geom_point() with geom_smooth()\n\n\n\n\n\n\n\nFigure¬†8: geom_tile()"
  },
  {
    "objectID": "lectures/grammar_of_graphics.html#position-scales-and-axes",
    "href": "lectures/grammar_of_graphics.html#position-scales-and-axes",
    "title": "Grammar of Graphics",
    "section": "Position scales and axes",
    "text": "Position scales and axes\nNumeric position scales\n\n\n\nLimit\n\n\nggplot(airquality, aes(x = Wind, y = Temp)) +\n  geom_point() +\n  scale_x_continuous(limits = c(0,15)) +\n  scale_y_continuous(limits = c(60,80))\n\n\n\n\n\n\nBreaks\n\n\nggplot(airquality,aes(x = Wind, y = Temp)) +\n  geom_point() +\n  scale_x_continuous(breaks = seq(from = 0, to = 20, by = 2)) +\n  scale_y_continuous(breaks = seq(from = 0, to = 100, by = 5))"
  },
  {
    "objectID": "lectures/grammar_of_graphics.html#position-scales-and-axes-1",
    "href": "lectures/grammar_of_graphics.html#position-scales-and-axes-1",
    "title": "Grammar of Graphics",
    "section": "Position scales and axes",
    "text": "Position scales and axes\nNumeric position scales (2)\n\n\n\nExpand\n\n\nggplot(airquality,\n       aes(x = Temp, \n           group = as.factor(Month), \n           fill = as.factor(Month))) +\n  geom_density(alpha = 0.6) +\n  scale_y_continuous(expand = c(0,0)) +\n  scale_x_continuous(expand = c(0,0))\n\n\n\n\n\n\nlog transformation\n\n\nggplot(diamonds,\n       aes(x = carat, y = price, color = cut)) +\n  geom_point(alpha = 0.6) +\n  scale_y_log10()"
  },
  {
    "objectID": "lectures/grammar_of_graphics.html#position-scales-and-axes-2",
    "href": "lectures/grammar_of_graphics.html#position-scales-and-axes-2",
    "title": "Grammar of Graphics",
    "section": "Position scales and axes",
    "text": "Position scales and axes\nDate-time position scale\n\n\n\nggplot(economics, aes(x = date, y = psavert)) + \n  geom_line(na.rm = TRUE) +\n  scale_x_date(date_breaks = \"15 years\")\n\n\n\n\n\n\nlim &lt;- as.Date(c(\"2004-01-01\", \"2005-01-01\"))\nggplot(economics, aes(x = date, y = psavert)) + \n  geom_line(na.rm = TRUE) +\n  scale_x_date(limits = lim, date_labels = \"%B\\n%Y\")\n\n\n\n\n\n\nDate scales behave like numeric scales, it‚Äôs ordinal, but is often more convenient to use the date_labels argument with the predefined formats. More available formatting strings: https://ggplot2-book.org/scales-position.html#sec-date-labels."
  },
  {
    "objectID": "lectures/grammar_of_graphics.html#position-scales-and-axes-3",
    "href": "lectures/grammar_of_graphics.html#position-scales-and-axes-3",
    "title": "Grammar of Graphics",
    "section": "Position scales and axes",
    "text": "Position scales and axes\nBinned position scales\n\nggplot(airquality, aes(x = Month, y = Ozone, color = Ozone)) +\n  geom_count(na.rm = TRUE) +\n  scale_y_binned(n.breaks = 10)"
  },
  {
    "objectID": "lectures/grammar_of_graphics.html#color-scales-and-legends",
    "href": "lectures/grammar_of_graphics.html#color-scales-and-legends",
    "title": "Grammar of Graphics",
    "section": "Color scales and legends",
    "text": "Color scales and legends\nColor blindness\nAvailable color palettes from package colorBlindness.\n\n# Load package\nlibrary(colorBlindness)\ndisplayAvailablePalette(color=\"white\")\n\n\nMore information on R colorBlindness package: https://cran.r-project.org/web/packages/colorBlindness/vignettes/colorBlindness.html"
  },
  {
    "objectID": "lectures/grammar_of_graphics.html#color-scales-and-legends-1",
    "href": "lectures/grammar_of_graphics.html#color-scales-and-legends-1",
    "title": "Grammar of Graphics",
    "section": "Color scales and legends",
    "text": "Color scales and legends\nContinuous color scales: viridis color palettes\n\nerupt &lt;- ggplot(faithfuld, aes(waiting, eruptions, fill = density)) +\n  geom_raster() + scale_x_continuous(NULL, expand = c(0, 0)) + scale_y_continuous(NULL, expand = c(0, 0))\n# Plot\nerupt\nerupt + scale_fill_viridis_c(option = \"viridis\")\nerupt + scale_fill_viridis_c(option = \"magma\")\nerupt + scale_fill_viridis_c(option = \"plasma\")\nerupt + scale_fill_viridis_c(option = \"rocket\")\nerupt + scale_fill_viridis_c(option = \"turbo\")\n\n\n\n\n\n\ndefault continuous palette\n\n\n\n\n\n\n\nviridis - viridis\n\n\n\n\n\n\n\nviridis - magma\n\n\n\n\n\n\n\n\n\nviridis - plasma\n\n\n\n\n\n\n\nviridis - rocket\n\n\n\n\n\n\n\nviridis - turbo"
  },
  {
    "objectID": "lectures/grammar_of_graphics.html#color-scales-and-legends-2",
    "href": "lectures/grammar_of_graphics.html#color-scales-and-legends-2",
    "title": "Grammar of Graphics",
    "section": "Color scales and legends",
    "text": "Color scales and legends\nContinuous color scales: distiller color palettes\n\nerupt + scale_fill_distiller(palette = \"RdBu\")\nerupt + scale_fill_distiller(palette = \"Pastel1\")\nerupt + scale_fill_distiller(palette = \"OrRd\")\n\n\n\n\n\n\ndistiller - Diverging\n\n\n\n\n\n\n\ndistiller - Qualitative\n\n\n\n\n\n\n\ndistiller - Sequential\n\n\n\n\n\n\nThe distiller scales applied brewer color palettes by by smoothly interpolating 7 colors from any palette to a continuous scale. For more brewer color palettes, see https://colorbrewer2.org."
  },
  {
    "objectID": "lectures/grammar_of_graphics.html#color-scales-and-legends-3",
    "href": "lectures/grammar_of_graphics.html#color-scales-and-legends-3",
    "title": "Grammar of Graphics",
    "section": "Color scales and legends",
    "text": "Color scales and legends\nContinuous color scales: ggsci color palettes\n\nlibrary(ggsci)\ndt_hm &lt;- scale(as.matrix(mtcars)[1:10, ], center = TRUE, scale = TRUE)\np_hm &lt;- as.data.frame(dt_hm) %&gt;% rownames_to_column(var = \"cars\") %&gt;% \n  pivot_longer(!cars) %&gt;%\n  ggplot(aes(x = name, y = cars, fill = value)) +\n  geom_tile(color = \"black\") +\n  coord_equal() +\n  labs(x=NULL, y = NULL) +\n  theme(legend.position = \"none\",\n        axis.text.x = element_blank())\n\np_hm\np_hm + scale_fill_gsea()\np_hm + scale_fill_material(\"yellow\")\np_hm + scale_fill_material(\"grey\")\n\n\n\n\n\n\nDefault heatmap color\n\n\n\n\n\n\n\nggsci - GSEA\n\n\n\n\n\n\n\nggsci - material (red)\n\n\n\n\n\n\n\nggsci - material (grey)\n\n\n\n\n\n\nDiscover more continuous ggsci color palette: https://cran.r-project.org/web/packages/ggsci/vignettes/ggsci.html"
  },
  {
    "objectID": "lectures/grammar_of_graphics.html#color-scales-and-legends-4",
    "href": "lectures/grammar_of_graphics.html#color-scales-and-legends-4",
    "title": "Grammar of Graphics",
    "section": "Color scales and legends",
    "text": "Color scales and legends\nMore Continuous color scales: paletteer color palettes\n\nerupt + scale_fill_paletteer_c(\"ggthemes::Green-Blue Diverging\")\nerupt + scale_fill_paletteer_c(\"ggthemes::Red-Blue-White Diverging\")\nerupt + scale_fill_paletteer_c(\"ggthemes::Temperature Diverging\")\nerupt + scale_fill_paletteer_c(\"grDevices::rainbow\")\nerupt + scale_fill_paletteer_c(\"grDevices::heat.colors\")\nerupt + scale_fill_paletteer_c(\"grDevices::Viridis\")\n\n\n\n\n\n\nggthemes::Green-Blue Diverging\n\n\n\n\n\n\n\nggthemes::Red-Blue-White Diverging\n\n\n\n\n\n\n\nggthemes::Temperature Diverging\n\n\n\n\n\n\n\n\n\ngrDevices::rainbow\n\n\n\n\n\n\n\ngrDevices::heat.colors\n\n\n\n\n\n\n\ngrDevices::Viridis\n\n\n\n\n\n\nMore continuous paletteer color palettes can be found at: https://pmassicotte.github.io/paletteer_gallery."
  },
  {
    "objectID": "lectures/grammar_of_graphics.html#color-scales-and-legends-5",
    "href": "lectures/grammar_of_graphics.html#color-scales-and-legends-5",
    "title": "Grammar of Graphics",
    "section": "Color scales and legends",
    "text": "Color scales and legends\nDiscrete color scales: default palette\n\ndf &lt;- data.frame(x = c(\"a\", \"b\", \"c\", \"d\",\"e\"), y = c(3, 4, 1, 2,5))\nbars &lt;- ggplot(df, aes(x, y, fill = x)) + \n  geom_bar(stat = \"identity\", color = \"black\") + \n  labs(x = NULL, y = NULL) +\n  theme(legend.position = \"none\")\n\nbars\nbars + scale_fill_hue()"
  },
  {
    "objectID": "lectures/grammar_of_graphics.html#color-scales-and-legends-6",
    "href": "lectures/grammar_of_graphics.html#color-scales-and-legends-6",
    "title": "Grammar of Graphics",
    "section": "Color scales and legends",
    "text": "Color scales and legends\nDiscrete color scales: RColorBrewer palettes\n\nbars + scale_fill_brewer(palette = \"BrBG\")\nbars + scale_fill_brewer(palette = \"RdYlGn\")\nbars + scale_fill_brewer(palette = \"Dark2\")\n\n\n\n\n\n\nDiverging - BrBG\n\n\n\n\n\n\n\nDiverging - RdYlGn\n\n\n\n\n\n\n\nSequential - Dark2\n\n\n\n\n\n\nInteractive RColorBrewer picker: https://colorbrewer2.org"
  },
  {
    "objectID": "lectures/grammar_of_graphics.html#color-scales-and-legends-7",
    "href": "lectures/grammar_of_graphics.html#color-scales-and-legends-7",
    "title": "Grammar of Graphics",
    "section": "Color scales and legends",
    "text": "Color scales and legends\nDiscrete color scales: ggsci palettes\nggsci offers high-quality color palettes based on color schemes used in scientific journals, data visualization libraries, and science fiction movies.\n\nbars + scale_fill_aaas()\nbars + scale_fill_npg()\nbars + scale_fill_nejm()\nbars + scale_fill_frontiers()\nbars + scale_fill_rickandmorty()\nbars + scale_fill_flatui()\nbars + scale_fill_startrek()\nbars + scale_fill_simpsons()\n\n\n\n\n\n\nInspired by Science\n\n\n\n\n\n\n\nInspired by Nature\n\n\n\n\n\n\n\nInspired by NEJM\n\n\n\n\n\n\n\nInspired by Frontiers\n\n\n\n\n\n\n\n\n\nInspired by Rick & Morty\n\n\n\n\n\n\n\nInspired by Flat UI design\n\n\n\n\n\n\n\nInspired by Startrek\n\n\n\n\n\n\n\nInspired by The Simpsons"
  },
  {
    "objectID": "lectures/grammar_of_graphics.html#color-scales-and-legends-8",
    "href": "lectures/grammar_of_graphics.html#color-scales-and-legends-8",
    "title": "Grammar of Graphics",
    "section": "Color scales and legends",
    "text": "Color scales and legends\nMore discrete color scales from paletteer\n\nbars + scale_fill_paletteer_d(\"awtools::bpalette\")\nbars + scale_fill_paletteer_d(\"basetheme::ink\")\nbars + scale_fill_paletteer_d(\"calecopal::kelp1\")\nbars + scale_fill_paletteer_d(\"fishualize::Centropyge_loricula\")\n\n\n\n\n\n\nawtools::bpalette\n\n\n\n\n\n\n\nbasetheme::ink\n\n\n\n\n\n\n\ncalecopal::kelp1\n\n\n\n\n\n\n\nfishualize::Centropyge_loricula\n\n\n\n\n\n\nInteractive discrete paletteer color palette: https://emilhvitfeldt.github.io/r-color-palettes/discrete.html"
  },
  {
    "objectID": "lectures/grammar_of_graphics.html#color-scales-and-legends-9",
    "href": "lectures/grammar_of_graphics.html#color-scales-and-legends-9",
    "title": "Grammar of Graphics",
    "section": "Color scales and legends",
    "text": "Color scales and legends\nManual discrete color scale\n\nbars + \n  scale_fill_manual(values = c(\"sienna1\", \"sienna4\", \n                               \"hotpink1\", \"hotpink4\", \"salmon\"))\nbars + scale_fill_manual(values = c(\"a\" = \"#C62828\", \"b\" = \"#9C27B0\",\n                                    \"c\" = \"#2196F3\", \"d\" = \"#4CAF50\",\n                                    \"e\" = \"#FF9800\"))"
  },
  {
    "objectID": "lectures/grammar_of_graphics.html#color-scales-and-legends-10",
    "href": "lectures/grammar_of_graphics.html#color-scales-and-legends-10",
    "title": "Grammar of Graphics",
    "section": "Color scales and legends",
    "text": "Color scales and legends\nAlpha\nThe alpha scale maps shade transparency to a numerical value.\n\nggplot(faithfuld, aes(waiting, eruptions, alpha = density)) +\n  geom_raster(fill = \"maroon\") +\n  scale_x_continuous(expand = c(0, 0)) + \n  scale_y_continuous(expand = c(0, 0))\nggplot(mtcars, aes(x = disp, y = mpg)) +\n  geom_point(size = 4, alpha = 0.3, color = \"blue\")"
  },
  {
    "objectID": "lectures/grammar_of_graphics.html#color-scales-and-legends-11",
    "href": "lectures/grammar_of_graphics.html#color-scales-and-legends-11",
    "title": "Grammar of Graphics",
    "section": "Color scales and legends",
    "text": "Color scales and legends\nLegend positions\n\nbars + theme(legend.position = \"left\")\nbars + theme(legend.position = \"right\")\nbars + theme(legend.position = \"top\")\nbars + theme(legend.position = \"bottom\")\nbars + theme(legend.position = \"none\")"
  },
  {
    "objectID": "lectures/grammar_of_graphics.html#references",
    "href": "lectures/grammar_of_graphics.html#references",
    "title": "Grammar of Graphics",
    "section": "References",
    "text": "References\n\nggplot2: Elegant Graphics for Data Analysis (3e): written by Hadley Wickham, Danielle Navarro, and Thomas Lin Pedersen (2023).\nIntroduction to data visualisation with ggplot2 Workshop: by QCBS R Workshop Series, 2023-04-24\nFundamentals of Data Visualization: by Claus O. Wilke, 2019\n\n\n\n\n17 May 2023\n\n\n\nWilke, Claus O. 2019. Fundamentals of Data Visualization. https://clauswilke.com/dataviz/."
  },
  {
    "objectID": "lectures/directory_of_visualizations.html",
    "href": "lectures/directory_of_visualizations.html",
    "title": "Directory of Visualizations",
    "section": "",
    "text": "In this chapter, we‚Äôll look at some of the most common plots and charts. We‚Äôll discuss how to interpret and use these visualizations to make data-driven decisions. We‚Äôll also explore how to create these plots and charts using ggplot2 and other graphic libraries.\nThe following commands will check whether the required R libraries already installed, if not, pacman will install and load the required libraries into your environment.\n# Install pacman\nif (!require(\"pacman\"))\n  install.packages(\"pacman\"\n  )\n\n# Use pacman p_load() to install and load other R libraries\npacman::p_load(\n1  tidyverse,\n2  viridis,\n3  ggsci,\n4  ComplexHeatmap,\n5  RColorBrewer,\n6  GGally,\n7  kableExtra,\n8  ggridges,\n9  factoextra\n)\n\n\n1\n\nAn integrated data management and visualization library.\n\n2\n\nColor palettes for continuous and discrete variables, color blind friendly.\n\n3\n\nColor palettes based on scientific journals, movies, TV shows.\n\n4\n\nFor visualizing heat maps and several plots alongside the heat maps. Provides powerful customization capabilities over the ggplot2‚Äôs geom_tile() and base heatmap() functions.\n\n5\n\nColor palettes for continuous and discrete variables.\n\n6\n\nExtension library of ggplot2. Plot complex plots in small steps by simplifying the commands. For exploratory data analysis and correlation analysis.\n\n7\n\nJust for render this document.\n\n8\n\nFor ridgeline plot\n\n9\n\nFor principal component analysis and visualization"
  },
  {
    "objectID": "lectures/directory_of_visualizations.html#visualizing-amounts",
    "href": "lectures/directory_of_visualizations.html#visualizing-amounts",
    "title": "Directory of Visualizations",
    "section": "1 Visualizing Amounts",
    "text": "1 Visualizing Amounts\n\n1.1 Bar Plots\nThe bar plot is the most common way to visualize amounts, i.e., how many things you‚Äôve already counted. Bar plots are versatile and easy to interpret. They are helpful for comparing various groupings of data. They can also be used to compare different values within the same dataset.\nIn this demo, we will create a data frame with two columns, name and value.\n\n# Create data\ndata_1 &lt;- data.frame(name = c(\"A\", \"B\", \"C\", \"D\", \"E\"), \n                   value = c(3, 12, 5, 18, 45))\n\n\n\n\nExample of data_1 \n\n\nname\nvalue\n\n\n\n\nA\n3\n\n\nB\n12\n\n\nC\n5\n\n\nD\n18\n\n\nE\n45\n\n\n\n\n\n\n\n\n1.1.1 Basic bar plot\nTo create bar plot with ggplot2:\n\nCall ggplot().\nSpecify the data object.\nMake the aesthetics function: use a categorical variable name for X axis and numeric value for Y axis, and fill the bar plot with color by the names of the categories name.\nfinally call geom_bar(). You have to specify stat=\"identity\" for this kind of data set.\nIn this case, use labs() to change the axes names, as well as legend name.\n\n\nggplot(data_1, aes(x = name, y = value, fill = name)) +\n  geom_bar(stat = \"identity\") +\n  labs(x = \"New name\", y = \"New value\") +\n  scale_fill_npg() +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n1.1.2 Horizontal bar plot\nTo rotate the plot to another orientation, use coord_flip().\n\nggplot(data_1, aes(x = name, y = value, fill = name)) +\n  geom_bar(stat = \"identity\") +\n  labs(x = \"New name\", y = \"New value\") +\n  coord_flip() +\n  scale_fill_npg() +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n1.1.3 Bar plot with labeled text\nTo annotate the number in each bar plot, add geom_text to the command. Specify the variable you want to show the text in aes() of geom_text. You can adjust the labels‚Äô position using hjust and vjust to move them in horizontal and vertical directions, respectively.\n\nggplot(data_1, aes(x = name, y = value, fill = name)) +\n  geom_bar(stat = \"identity\") +\n  geom_text(aes(label = value), vjust = -0.2) +\n  labs(x = \"New name\", y = \"New value\")+\n  scale_fill_npg() +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n1.2 Grouped and Stacked Bar Plot\nWe showed how to visualize quantitative amounts in a single variable in the previous section. Sometimes we‚Äôre interested in two categorical variables at once. For example, the mock data frame data_plant that collects data from multiple plant species and multiple conditions.\n\n# create a dataset\nset.seed(123456)\ndata_plant &lt;- data.frame(\n  species = c(rep(\"sorgho\", 3),\n              rep(\"poacee\", 3),\n              rep(\"banana\", 3),\n              rep(\"triticum\", 3)),\n  condition = rep(c(\"normal\", \"stress\", \"Nitrogen\"), 4),\n  value = abs(rnorm(12, 0, 15)))\n\n\n\n\nExample of data_plant \n\n\nspecies\ncondition\nvalue\n\n\n\n\nsorgho\nnormal\n12.505998\n\n\nsorgho\nstress\n4.140717\n\n\nsorgho\nNitrogen\n5.325028\n\n\npoacee\nnormal\n1.312311\n\n\npoacee\nstress\n33.783836\n\n\npoacee\nNitrogen\n12.516902\n\n\n\n\n\n\n\n\n1.2.1 Grouped bar plot\nIn the geom_bar(), use the argument position=\"dodge\" to position the bars next to each other.\n\nggplot(data_plant, aes(fill = condition, y = value, x = species)) +\n  geom_bar(position = \"dodge\", stat = \"identity\")+\n  scale_fill_npg() +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n1.2.2 Small multiple bar plots\nTo make multiple bar plots, use facet_wrap(). Each panel will have its name defined by the variable specified. facet_wrap() fixes x and/or y axes scales using the argument scales.\n\nggplot(data_plant, aes(fill = condition, y = value, x = species)) +\n  geom_bar(position = \"dodge\", stat = \"identity\") +\n  facet_wrap( ~ species, scales = \"free_x\") +\n  scale_fill_npg()\n\n\n\n\n\n\n1.2.3 Stacked bar plot\nStack bar plots display subgroups on top of each other. The only thing to change to get this figure is to switch the position argument to stack by adding position = \"stack\" to the geom_bar() function.\n\nggplot(data_plant, aes(fill = condition, y = value, x = species)) +\n  geom_bar(position = \"stack\", stat = \"identity\") +\n  scale_fill_npg()\n\n\n\n\n\n\n1.2.4 Percent stacked bar plot\nChange the position of the percent stacked bar plot to ‚Äúfill‚Äù. We can now study the evolution of each subgroup‚Äôs proportion in the overall sample by looking at the percentage of each subgroup.\n\nggplot(data_plant, aes(fill = condition, y = value, x = species)) +\n  geom_bar(position = \"fill\", stat = \"identity\") +\n  scale_fill_npg()\n\n\n\n\n\n\n\n1.3 Dot Plots\nBars have a limitation that they need to start at zero, so the length is proportional to the amount. Your plot would be vague. We can indicate amounts by placing dots along the x or y axis.\n\n\n\n\n\n\ndot plot vs scatter plot\n\n\n\nA dot plot is a graph that uses dots to indicate the frequency or amount of a certain value. This makes it easier to compare values, as the dots line up along a continuous axis. A scatter plot, on the other hand, uses points to represent two different variables. This makes it easier to identify the relationship between the two variables.\n\n\n\n1.3.1 Simple dot plot\nWe‚Äôll show you a simple dot plot on US precipitation. Start by loading the data into R and selecting the 30 most precipitated cities in the US.\n\n# Prepare data of Annual Precipitation in US Cities\nUS_precip &lt;- data.frame(city = names(precip), precipitation = precip)\nUS_precip &lt;- US_precip %&gt;% \n  top_n(n = 30) %&gt;%\n  arrange(desc(precipitation))\n\nSelecting by precipitation\n\n\n\n\n\nExample of US_precip data \n\n\ncity\nprecipitation\n\n\n\n\nMobile\n67.0\n\n\nMiami\n59.8\n\n\nSan Juan\n59.2\n\n\nNew Orleans\n56.8\n\n\nJuneau\n54.7\n\n\nJacksonville\n54.5\n\n\nJackson\n49.2\n\n\nMemphis\n49.1\n\n\nLittle Rock\n48.5\n\n\nAtlanta\n48.3\n\n\nHouston\n48.2\n\n\nColumbia\n46.4\n\n\nNashville\n46.0\n\n\nAtlantic City\n45.5\n\n\nNorfolk\n44.7\n\n\nHartford\n43.4\n\n\nLouisville\n43.1\n\n\nProvidence\n42.8\n\n\nCharlotte\n42.7\n\n\nRichmond\n42.6\n\n\nBoston\n42.5\n\n\nRaleigh\n42.5\n\n\nBaltimore\n41.8\n\n\nPortland\n40.8\n\n\nCharleston\n40.8\n\n\nWilmington\n40.2\n\n\nNew York\n40.2\n\n\nPhiladelphia\n39.9\n\n\nCincinnati\n39.0\n\n\nWashington\n38.9\n\n\n\n\n\n\n\nThe plot will be a value-ordered dot plot. Basically, ggplot2 will arrange the data alphabetically or ascendingly arranged. It won‚Äôt work if you order the data frame before defining ggplot(). Instead, you can arrange the data using reorder(variable_to_order, variable_to_rely_on) during aesthetics mapping as follows.\n\n# Plot value-ordered dot plot\nggplot(US_precip, aes(x = precipitation, y = reorder(city, precipitation))) +\n  geom_point(size = 3,\n             alpha = 0.8,\n             color = \"#D51317\") +\n  labs(x = \"Average annual precipitation (in.)\", y = NULL) +\n  theme_bw()\n\n\n\n\n\n\n1.3.2 Time-series\nTime can be considered as one of the variables, and it is in an inherent order. Line graphs help us visualize this temporal order. Line graphs can be used to show trends over time, allowing us to compare values at different points in time. They are useful for highlighting changes in data ove\nWe will use the USPersonalExpenditure data set. This data set consists of United States personal expenditures (in billions of dollars) in the categories; food and tobacco, household operation, medical and health, personal care, and private education for the years 1940, 1945, 1950, 1955 and 1960.\n\n# Prepare data\nUS_exp &lt;- data.frame(USPersonalExpenditure) %&gt;% \n  rownames_to_column(var = \"Category\") %&gt;% \n  pivot_longer(!Category) %&gt;% \n  mutate(name = gsub(\"X\", \"\", name)) %&gt;% \n  rename(year = name)\n\nggplot(US_exp, aes(x = year, y = value, group = Category, color = Category)) +\n  geom_line(linewidth = 0.7, color = \"black\") +\n  geom_point(size = 3) +\n  scale_color_frontiers() +\n  labs(x = \"Year\", y = \"Amount (billions dollars)\")\n\n\n\n\n\n\n\n1.4 Heatmaps\nAs an alternative to mapping data values onto positions via bars or dots, we can map data values onto colors. Such a figure is called a heat map. Which is a graphical representation of data where the individual values contained in a matrix are represented as colors.\n\n1.4.1 Basic Heatmap with base R\nThe heatmap() function is natively provided in R. Which required the data in a matrix format, them heatmap() is then run clustering algorithm and visualize the result with dendrogram. We cal use argument scale to normalize matrix to balance the heat colors for easy infer the trend of the data.\n\n# The mtcars dataset:\ndata &lt;- as.matrix(mtcars)\n\n# Default Heatmap\nheatmap(data)\n\n# Use 'scale' to normalize\nheatmap(data, scale=\"column\")\n\n\n\n\n\n\nMost basic heatmap\n\n\n\n\n\n\n\n\n\nScaled value by column\n\n\n\n\n\n\n\n\n1.4.2 Heatmap with geom_tile()\nWe will use USJudgeRatings data set, which reports Lawyers‚Äô Ratings of State Judges in the US Superior Court.\n\n# Prepare data\ndt_USJudgeRatings &lt;- USJudgeRatings %&gt;% \n  rownames_to_column(var = \"company\") %&gt;% \n  pivot_longer(!company)\nhead(dt_USJudgeRatings)\n\n# A tibble: 6 √ó 3\n  company       name  value\n  &lt;chr&gt;         &lt;chr&gt; &lt;dbl&gt;\n1 AARONSON,L.H. CONT    5.7\n2 AARONSON,L.H. INTG    7.9\n3 AARONSON,L.H. DMNR    7.7\n4 AARONSON,L.H. DILG    7.3\n5 AARONSON,L.H. CFMG    7.1\n6 AARONSON,L.H. DECI    7.4\n\n# Plot\nggplot(dt_USJudgeRatings, aes(x = name, y = company, fill = value)) +\n  geom_tile() +\n  scale_fill_distiller(palette = \"Reds\") +\n  labs(x = \"Features\", y = NULL)\n\n\n\n\n\n\n1.4.3 Heatmap with Heatmap() of ComplexHeatmap\nWith ComplexHeatmap you‚Äôre able to visualize associations between different data sources, reveal patterns, and arrange multiple heat maps in a way that‚Äôs highly flexible. In this analysis, we‚Äôll use the same data set as above, USJudgeRatings.\n\n# Prepare data\nmat_USJudgeRatings &lt;- as.matrix(USJudgeRatings)\n\n# Plot heatmap using ComplexHeatmap\nHeatmap(mat_USJudgeRatings,\n        row_names_gp = gpar(fontsize = 8),\n        column_names_gp = gpar(fontsize = 8),\n        column_names_rot = 30)"
  },
  {
    "objectID": "lectures/directory_of_visualizations.html#visualizing-distribution",
    "href": "lectures/directory_of_visualizations.html#visualizing-distribution",
    "title": "Directory of Visualizations",
    "section": "2 Visualizing Distribution",
    "text": "2 Visualizing Distribution\nIn a dataset, you might want to know how a variable is distributed. You can look at the distribution of a variable to get a better idea. Visualizations like histograms, boxplots, and density plots help with this. Data patterns and outliers can be identified this way. This can help you understand the data better, and draw conclusions from it. It can also help you decide which type of analysis to use. ### Histogram\nA histogram can be easily built with ggplot2‚Äôs geom_histogram() function. The input only needs one numerical variable. You might get a warning message during the plot regarding the bin width or stratification as explained in the next section.\n\n2.0.1 Basic histogram\nA histogram is created by binning data, or stratifying data into ranges of frequency, so how they look depends on the bin width. Bin widths are usually chosen by default in visualization programs.\n\n\n\n\n\n\nusers may have to pick the appropriate bin width by hand. The histogram gets too peaky and busy if the bin width is too small. There might be a lot of noise in the data. In contrast, too wide a bin width can blur smaller features in the data distribution, like the dip around age 10.\n\n\n\n\ndt_hist &lt;- data.frame(value = rnorm(100))\n\nggplot(iris, aes(x = Petal.Length)) +\n  geom_histogram(fill = \"salmon\", color = \"black\") +\n  labs(subtitle = \"bin width = 30 (default)\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\nggplot(iris, aes(x = Petal.Length)) +\n  geom_histogram(fill = \"salmon\", color = \"black\", bins = 15) +\n  labs(subtitle = \"bin width = 15\")\nggplot(iris, aes(x = Petal.Length)) +\n  geom_histogram(fill = \"salmon\", color = \"black\", bins = 40) +\n  labs(subtitle = \"bin width = 40\")\nggplot(iris, aes(x = Petal.Length)) +\n  geom_histogram(fill = \"salmon\", color = \"black\", bins = 5) +\n  labs(subtitle = \"bin width = 5\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.1 Density Plot\nThe density plot shows the underlying probability distribution of the data by drawing a continuous curve. An estimation procedure called kernel density estimation is commonly used to estimate this curve from the data. This estimation procedure is used to estimate the probability of the data falling within a particular range. The resulting curve is then plotted on a graph, allowing for easier comparison and analysis.\n\n2.1.1 Basic density plot\n\nggplot(iris, aes(x = Petal.Length)) +\n  geom_density(fill = \"grey80\") +\n  theme_bw()\n\n\n\n\n\n\n2.1.2 Multiple density plots\n\nggplot(iris, aes(x = Petal.Length, fill = Species)) +\n  geom_density(alpha = 0.7) +\n  scale_fill_npg()\n\n\n\n\n\n\n2.1.3 Facet density plots\n\nggplot(iris, aes(x = Petal.Length, fill = Species)) +\n  geom_density() +\n  scale_fill_viridis_d() +\n  facet_wrap(. ~ Species) +\n  scale_fill_npg()\n\nScale for fill is already present.\nAdding another scale for fill, which will replace the existing scale.\n\n\n\n\n\n\n\n\n2.2 Box Plot and Violin Plot\nA box plot gives a nice summary of one or more numeric variables. A boxplot is composed of several elements:\n\n\n\nAnatomy of box plot. Image from https://www.leansigmacorporation.com/box-plot-with-minitab\n\n\n\nA median is a line that divides the box into two parts. If the median is 10, it means there are the same number of data points above and below the line.\nThere are two quartiles at the ends of the box, the upper (Q3) and lower (Q1). A third quartile of 15 indicates that 75% of observations are below that level.\nThe difference between Quartiles 1 and 3 is called the interquartile range (IQR)\nThe extreme line shows Q3+1.5 x IQR to Q1-1.5 x IQR (the highest and lowest value excluding outliers). Dots (or other markers) beyond the extreme line shows potential outliers.\n\nHowever, you should keep in mind that data distribution is hidden behind each box. Normal distributions could look exactly like bimodal distributions. It is recommended to consider a violin plot or a ridgline chart instead.\nWe will demonstrate on ToothGrowth data set. The data set showed the Effect of Vitamin C on Tooth Growth in Guinea Pigs.\n\n\n\nExample of ToothGrowth data set \n\n\nlen\nsupp\ndose\n\n\n\n\n4.2\nVC\n0.5\n\n\n11.5\nVC\n0.5\n\n\n7.3\nVC\n0.5\n\n\n5.8\nVC\n0.5\n\n\n6.4\nVC\n0.5\n\n\n10.0\nVC\n0.5\n\n\n11.2\nVC\n0.5\n\n\n11.2\nVC\n0.5\n\n\n5.2\nVC\n0.5\n\n\n7.0\nVC\n0.5\n\n\n16.5\nVC\n1.0\n\n\n16.5\nVC\n1.0\n\n\n15.2\nVC\n1.0\n\n\n17.3\nVC\n1.0\n\n\n22.5\nVC\n1.0\n\n\n17.3\nVC\n1.0\n\n\n13.6\nVC\n1.0\n\n\n14.5\nVC\n1.0\n\n\n18.8\nVC\n1.0\n\n\n15.5\nVC\n1.0\n\n\n\n\n\n\n\n\nggplot(ToothGrowth, \n       aes(x = as.factor(dose), y = len, \n           fill = as.factor(dose), group = as.factor(dose))) +\n  geom_boxplot() +\n  scale_fill_npg() +\n  geom_jitter(color=\"grey30\", size=2, alpha=0.7, width = 0.2) +\n  labs(x = \"Dose (mg/day)\", y = \"Tooth length (mm)\") +\n  theme(legend.position = \"none\")\n\n\nggplot(ToothGrowth, \n       aes(x = as.factor(dose), y = len, \n           fill = as.factor(dose), group = as.factor(dose))) +\n  geom_violin() +\n  scale_fill_npg() +\n  geom_jitter(color=\"grey30\", size=2, alpha=0.7, width = 0.2) +\n  labs(x = \"Dose (mg/day)\", y = \"Tooth length (mm)\") +\n  theme(legend.position = \"none\")\n\nggplot(ToothGrowth, \n       aes(x = as.factor(dose), y = len, \n           fill = as.factor(dose), group = as.factor(dose))) +\n  geom_violin() +\n  scale_fill_npg() +\n  geom_boxplot(fill = \"white\", width = 0.2) +\n  labs(x = \"Dose (mg/day)\", y = \"Tooth length (mm)\") +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\nBox plot with jitters\n\n\n\n\n\n\n\nViolin plot with jitters\n\n\n\n\n\n\n\n\n\nBox with violin plot\n\n\n\n\n\n\n\n2.2.1 Ridgeline plot\nPrevious section showed how to visualize the distribution stack horizontally with histograms and density plots. To expand on this idea, we‚Äôll stagger the distribution plots vertically. Ridgeline plots look like mountain ridgelines, so they‚Äôre called that. The ridgeline plot is a good way to show trends in distributions. This example checks the distribution of diamond prices based on their quality.\nThis graph is made using the ggridges library, which is a ggplot2 extension and compatible with the syntax of the ggplot2. For the X axis, we specify the price column, and for the Y axis, we specify the cut column. By adding 'fill=cut', we can use one color per category and display them separately.\n\nggplot(diamonds, aes(x = price, y = cut, fill = cut)) +\n  geom_density_ridges() +\n  theme(legend.position = \"none\")\n\nPicking joint bandwidth of 458"
  },
  {
    "objectID": "lectures/directory_of_visualizations.html#visualizing-proportions",
    "href": "lectures/directory_of_visualizations.html#visualizing-proportions",
    "title": "Directory of Visualizations",
    "section": "3 Visualizing Proportions",
    "text": "3 Visualizing Proportions\nIn many cases, we want to show how something breaks down into parts that each represent a portion of the whole. Among data scientists, pie charts are often maligned because they are ubiquitous in business presentations.\n\n3.1 Pie and Donut Chart\n\n# Create Data\ndata &lt;- data.frame(\n  group=LETTERS[1:5],\n  value=c(13,7,9,21,2))\n\n\n\n\nExample of ToothGrowth data set \n\n\ngroup\nvalue\n\n\n\n\nA\n13\n\n\nB\n7\n\n\nC\n9\n\n\nD\n21\n\n\nE\n2\n\n\n\n\n\n\n\n\n# Basic piechart\nggplot(data, aes(x = \"\", y = value, fill = group)) +\n  geom_bar(stat = \"identity\",\n           width = 1,\n           color = \"white\") +\n  coord_polar(\"y\", start = 0) +\n  scale_fill_npg() +\n  theme_void() # remove background, grid, numeric labels\n\n\n\n\nTo create pie chart with data label\n\n# Piechart with data labels\n## Compute the position of labels\ndata_2 &lt;- data %&gt;% \n  arrange(desc(group)) %&gt;%\n  mutate(prop = value / sum(data$value) *100) %&gt;%\n  mutate(ypos = cumsum(prop)- 0.5*prop)\n\n\n\n\nExample of ToothGrowth data set \n\n\ngroup\nvalue\nprop\nypos\n\n\n\n\nE\n2\n3.846154\n1.923077\n\n\nD\n21\n40.384615\n24.038462\n\n\nC\n9\n17.307692\n52.884615\n\n\nB\n7\n13.461538\n68.269231\n\n\nA\n13\n25.000000\n87.500000\n\n\n\n\n\n\n\n\n# Plot\nggplot(data_2, aes(x=\"\", y=prop, fill=group)) +\n  geom_bar(stat=\"identity\", width=1, color=\"white\") +\n  coord_polar(\"y\", start=0) +\n  theme_void() + \n  theme(legend.position=\"none\") +\n  geom_text(aes(y = ypos, label = group), color = \"white\", size=6) +\n  scale_fill_npg()\n\n\n\n\nFor accurate representation of data, alternative plots like percent stacked bar charts or streamlined plots should be considered instead of pie charts. Pie charts can make it hard to compare fractions since the relative sizes are hard to see. So if you want a more accurate representation of the data, you should use another type of chart."
  },
  {
    "objectID": "lectures/directory_of_visualizations.html#visualizing-x-y-relationships",
    "href": "lectures/directory_of_visualizations.html#visualizing-x-y-relationships",
    "title": "Directory of Visualizations",
    "section": "4 Visualizing x-y Relationships",
    "text": "4 Visualizing x-y Relationships\nA dataset may contain two or more quantitative variables, and we might be interested in how they relate. In order to plot just the relationship between two variables, such as height and weight, we use a scatter plot. The bubble chart, scatter plot matrix, or correlogram are all good options if we want to show more than two variables at once. Further, principal component analysis is great for high-dimensional datasets, i.e., observing multiple variables at once.\n\n4.1 Scatter Plot\nIn a scatterplot, two variables are plotted along two axes. It shows how they‚Äôre related, eventually revealing a correlation. Here the relationship between Petal width and Petal length in iris data set will demonstrated.\n\n4.1.1 Basic scatter plot\n\nggplot(iris, aes(x = Petal.Width, y = Petal.Length, color = Species)) +\n  geom_point(alpha = 0.8, size = 2.5) +\n  labs(x = \"Petal width (cm)\",\n       y = \"Petal length (cm)\") +\n  scale_color_npg()\n\n\n\n\n\n\n4.1.2 Facet scatter plot\n\nggplot(iris, aes(x = Petal.Width, y = Petal.Length, color = Species)) +\n  geom_point(alpha = 0.8, size = 2.5) +\n  labs(x = \"Petal width (cm)\",\n       y = \"Petal length (cm)\") +\n  scale_color_npg() +\n  facet_wrap(. ~ Species)\n\n\n\n\n\n\n4.1.3 Scatter plot with trend line\nAdding a linear trend to a scatter plot helps the reader identify patterns. The linear trend also helps to identify outliers, as points that are far from the trend are easily visible. It can also be used to make predictions about future values based on current data. geom_smooth() in ggplot2 allows you to add the linear trend and confidence interval around it by using \"se = TRUE\"\n\nggplot(mtcars, aes(x = disp, y = mpg)) +\n  geom_point(alpha = 0.8, size = 2) +\n  geom_smooth(method = \"lm\", color = \"red\") +\n  labs(x = \"Miles/(US) gallon\",\n       y = \"Displacement (cu.in.)\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n4.2 Correlograms\nWhen we have more than three or four variables, all-against-all scatter plots get a little complicated. Rather than presenting raw data, it‚Äôs better to quantify the amount of association between pairs of variables. Correlation coefficients are a common way to do this.\nThe correlation coefficient r measures how much two variables correlate between -1 and 1. A value of r = 0 means there is no association whatsoever, and a value of 1 or -1 indicates an ideal association. There are two kinds of correlation coefficients: correlated (larger values in one variable coincide with larger values in the other) or anticorrelated (larger values in one variable coincide with smaller values in the other).\nHere‚Äôs a quick demonstration of all-against-all correlation analysis and a correlogram plotted using the mtcars data set.\n\n# Create data \ndata &lt;- data.frame(mtcars)\n \n# Check correlation between variables, default uses Pearson\ncor_mtcars &lt;- cor(data)\n\n\n\n\nExample of all-against-all correlation coefficient in mtcars data \n\n\n\nmpg\ncyl\ndisp\nhp\ndrat\nwt\nqsec\nvs\nam\ngear\ncarb\n\n\n\n\nmpg\n1.0000000\n-0.8521620\n-0.8475514\n-0.7761684\n0.6811719\n-0.8676594\n0.4186840\n0.6640389\n0.5998324\n0.4802848\n-0.5509251\n\n\ncyl\n-0.8521620\n1.0000000\n0.9020329\n0.8324475\n-0.6999381\n0.7824958\n-0.5912421\n-0.8108118\n-0.5226070\n-0.4926866\n0.5269883\n\n\ndisp\n-0.8475514\n0.9020329\n1.0000000\n0.7909486\n-0.7102139\n0.8879799\n-0.4336979\n-0.7104159\n-0.5912270\n-0.5555692\n0.3949769\n\n\nhp\n-0.7761684\n0.8324475\n0.7909486\n1.0000000\n-0.4487591\n0.6587479\n-0.7082234\n-0.7230967\n-0.2432043\n-0.1257043\n0.7498125\n\n\ndrat\n0.6811719\n-0.6999381\n-0.7102139\n-0.4487591\n1.0000000\n-0.7124406\n0.0912048\n0.4402785\n0.7127111\n0.6996101\n-0.0907898\n\n\nwt\n-0.8676594\n0.7824958\n0.8879799\n0.6587479\n-0.7124406\n1.0000000\n-0.1747159\n-0.5549157\n-0.6924953\n-0.5832870\n0.4276059\n\n\nqsec\n0.4186840\n-0.5912421\n-0.4336979\n-0.7082234\n0.0912048\n-0.1747159\n1.0000000\n0.7445354\n-0.2298609\n-0.2126822\n-0.6562492\n\n\nvs\n0.6640389\n-0.8108118\n-0.7104159\n-0.7230967\n0.4402785\n-0.5549157\n0.7445354\n1.0000000\n0.1683451\n0.2060233\n-0.5696071\n\n\nam\n0.5998324\n-0.5226070\n-0.5912270\n-0.2432043\n0.7127111\n-0.6924953\n-0.2298609\n0.1683451\n1.0000000\n0.7940588\n0.0575344\n\n\ngear\n0.4802848\n-0.4926866\n-0.5555692\n-0.1257043\n0.6996101\n-0.5832870\n-0.2126822\n0.2060233\n0.7940588\n1.0000000\n0.2740728\n\n\ncarb\n-0.5509251\n0.5269883\n0.3949769\n0.7498125\n-0.0907898\n0.4276059\n-0.6562492\n-0.5696071\n0.0575344\n0.2740728\n1.0000000\n\n\n\n\n\n\n\n\n# visualization of correlations\n## Squared correlogram\nggcorr(data, method = c(\"everything\", \"pearson\")) \n\n\n\n## Circle correlogram\nggcorr(data, method = c(\"everything\", \"pearson\"), \n       geom = \"circle\",\n       min_size = 5,\n       max_size = 10)\n\n\n\n\n\n\n4.3 Dimension Reduction\nHigh-dimensional datasets commonly have multiple correlated variables that convey overlapping information, so dimension reduction relies on that. A smaller number of key dimensions can be reduced without losing data characteristics.\nThere are many dimension reduction techniques. But, the most widely used method is principal components analysis (PCA) for exploring the data. PCA introduces an additional set of variables (called principal components, PCs) by linear combination of the original variables in the data, standardized to zero mean and unit variance. PCs are chosen to be uncorrelated, and they are ordered so the first component captures the most variation in the data, and each subsequent component captures less and less. In most cases, you can see the key features of data from the first two or three PCs.\nWe‚Äôll show you how to compute and visualize PCA in R using the prcomp() function and the factoextra package. To show PCA, the factoextra‚Äôs built-in data, a Decathlon2.active, will be used.\n\n# Prepare data\ndata(decathlon2)\ndecathlon2.active &lt;- decathlon2[1:23, 1:10]\n\n\n\n\n\n\n\nX100m\nLong.jump\nShot.put\nHigh.jump\nX400m\nX110m.hurdle\nDiscus\nPole.vault\nJaveline\nX1500m\n\n\n\n\nSEBRLE\n11.04\n7.58\n14.83\n2.07\n49.81\n14.69\n43.75\n5.02\n63.19\n291.7\n\n\nCLAY\n10.76\n7.40\n14.26\n1.86\n49.37\n14.05\n50.72\n4.92\n60.15\n301.5\n\n\nBERNARD\n11.02\n7.23\n14.25\n1.92\n48.93\n14.99\n40.87\n5.32\n62.77\n280.1\n\n\nYURKOV\n11.34\n7.09\n15.19\n2.10\n50.42\n15.31\n46.26\n4.72\n63.44\n276.4\n\n\nZSIVOCZKY\n11.13\n7.30\n13.48\n2.01\n48.62\n14.17\n45.67\n4.42\n55.37\n268.0\n\n\nMcMULLEN\n10.83\n7.31\n13.76\n2.13\n49.91\n14.38\n44.41\n4.42\n56.37\n285.1\n\n\nMARTINEAU\n11.64\n6.81\n14.57\n1.95\n50.14\n14.93\n47.60\n4.92\n52.33\n262.1\n\n\nHERNU\n11.37\n7.56\n14.41\n1.86\n51.10\n15.06\n44.99\n4.82\n57.19\n285.1\n\n\nBARRAS\n11.33\n6.97\n14.09\n1.95\n49.48\n14.48\n42.10\n4.72\n55.40\n282.0\n\n\nNOOL\n11.33\n7.27\n12.68\n1.98\n49.20\n15.29\n37.92\n4.62\n57.44\n266.6\n\n\n\n\n\n\n\n\n# Calculate principal components\nres.pca &lt;- prcomp(decathlon2.active, scale = TRUE)\n# Summarize PCA\nsummary(res.pca)\n\nImportance of components:\n                          PC1    PC2    PC3     PC4     PC5     PC6     PC7\nStandard deviation     2.0308 1.3559 1.1132 0.90523 0.83759 0.65029 0.55007\nProportion of Variance 0.4124 0.1839 0.1239 0.08194 0.07016 0.04229 0.03026\nCumulative Proportion  0.4124 0.5963 0.7202 0.80213 0.87229 0.91458 0.94483\n                           PC8     PC9   PC10\nStandard deviation     0.52390 0.39398 0.3492\nProportion of Variance 0.02745 0.01552 0.0122\nCumulative Proportion  0.97228 0.98780 1.0000\n\n\nShow the percentage of variance explained by each principal component using eigenvalues (scree plot).\n\n# Visualizing scree plot\nfviz_eig(res.pca) + theme_grey()\n\n\n\n\nVisualize graph of individuals. Individuals with a similar profile are grouped together.\n\n# Individual PCA\nfviz_pca_ind(res.pca,\n             col.ind = \"cos2\", # Color by the quality of representation\n             gradient.cols = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\"),\n             repel = TRUE     # Avoid text overlapping\n             )\n\n\n\n\nGraph of variables. Positive correlated variables point to the same side of the plot. Negative correlated variables point to opposite sides of the graph.\n\n# Variable PCA\nfviz_pca_var(res.pca,\n             col.var = \"contrib\", # Color by contributions to the PC\n             gradient.cols = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\"),\n             repel = TRUE     # Avoid text overlapping\n             )\n\n\n\n\nBiplot of individuals and variables\n\n# Biplot\nfviz_pca_biplot(res.pca, repel = TRUE,\n                col.var = \"#FC4E07\", # Variables color\n                col.ind = \"#696969\"  # Individuals color\n                )"
  },
  {
    "objectID": "lectures/directory_of_visualizations.html#references",
    "href": "lectures/directory_of_visualizations.html#references",
    "title": "Directory of Visualizations",
    "section": "5 References",
    "text": "5 References\n\nFundamentals of Data Visualization: by Claus O. Wilke, 2019\nR Graphics Cookbook, 2nd edition. Winston Chang, 2023.\nPrincipal Component Analysis in R: prcomp vs princomp from STHDA, 2017."
  },
  {
    "objectID": "lectures/plotting_omics_data.html",
    "href": "lectures/plotting_omics_data.html",
    "title": "Plotting Omics Data",
    "section": "",
    "text": "pacman::p_load(\n  \"tidyverse\",\n  \"kableExtra\",\n  \"openxlsx\",\n  \"DESeq2\",\n  \"pcaExplorer\",\n  \"factoextra\",\n  \"ggsci\",\n  \"ComplexHeatmap\",\n  \"RColorBrewer\",\n  \"EnhancedVolcano\",\n  \"ggvenn\", \n  \"ggpubr\",\n  \"kableExtra\"\n  )"
  },
  {
    "objectID": "lectures/plotting_omics_data.html#load-libraries",
    "href": "lectures/plotting_omics_data.html#load-libraries",
    "title": "Plotting Omics Data",
    "section": "",
    "text": "pacman::p_load(\n  \"tidyverse\",\n  \"kableExtra\",\n  \"openxlsx\",\n  \"DESeq2\",\n  \"pcaExplorer\",\n  \"factoextra\",\n  \"ggsci\",\n  \"ComplexHeatmap\",\n  \"RColorBrewer\",\n  \"EnhancedVolcano\",\n  \"ggvenn\", \n  \"ggpubr\",\n  \"kableExtra\"\n  )"
  },
  {
    "objectID": "lectures/plotting_omics_data.html#plotting-abundance-of-representative-terms",
    "href": "lectures/plotting_omics_data.html#plotting-abundance-of-representative-terms",
    "title": "Plotting Omics Data",
    "section": "2 Plotting Abundance of Representative Terms",
    "text": "2 Plotting Abundance of Representative Terms\n\n# Load COG dictionary\n1COG_dict &lt;- read_delim(\"https://github.com/JirathNuan/r-handviz-workshop/raw/main/datasets/cog_category.txt\")\n\n# Load eggNOG-mapper result\n2emapper_dt &lt;- read.xlsx(\"https://github.com/JirathNuan/r-handviz-workshop/raw/main/datasets/Dme_chr4.emapper.annotations.xlsx\",\n                        startRow = 3, \n                        cols = 7) %&gt;% \n3  filter(COG_category != \"-\") %&gt;%\n4  group_by(COG_category) %&gt;%\n5  summarize(n = n()) %&gt;%\n6  left_join(COG_dict, by = c(\"COG_category\" = \"category\")) %&gt;%\n7  mutate(label = paste0(COG_category, \": \", category_name))\n\n# Show first 10 lines of data frame\nhead(emapper_dt, 10) %&gt;% kbl() %&gt;% kable_styling(full_width = FALSE)\n  \n# Plot\n8ggplot(emapper_dt, aes(x = COG_category, y = n, fill = label)) +\n9  geom_bar(stat = \"identity\") +\n10  scale_y_continuous(breaks = seq(0, 100, 10)) +\n11  labs(x = \"COG category\",\n       y = \"Number of sequences\", \n       fill = \"COG category\") +\n12  theme(legend.key.size = unit(0.5, 'cm'))\n\n\n1\n\ncog_category.txt is a cluster of orthologous groups (COG) dictionary. Use for look up the category names into the plot.\n\n2\n\nRead eggNOG-mapper result from excel file into emapper_dt, using read.xlsx() from openxlsx library. The excel is read by skipping the first 3 rows and select only 7th column.\n\n3\n\nThen, go to the next step by pipe %&gt;%. This step it to filter unclassified COGs - from the COG_category using dplyr filter().\n\n4\n\nThen group the data frame by COG_category.\n\n5\n\nCount number of COGs presented in this eggNOG-mapper result.\n\n6\n\nMerge COG dictionary into the result using dplyr left_join(). Two data frames are merged by matching the column COG_category from emapper_dt with the column category of COG_dict.\n\n7\n\nThen, add new column label for the plot legend, by append COG category together with the category name.\n\n8\n\nPlot the result from by showing COG_category in x-axis, number of COGs n in y-axis, fill and add legend by column label.\n\n9\n\nPlot bar plot using geom_bar() and stat = \"identity\"\n\n10\n\nSet y-axis breaks\n\n11\n\nCustomize label of x- and y-axis, and legend name in fill.\n\n12\n\nAdjust size of legend using theme(legend.key.size).\n\n\n\n\n\n\n\n\nFirst 10 lines of the number of COG category results. \n\n\nCOG_category\nn\ncategory_name\nlabel\n\n\n\n\nA\n5\nRNA processing and modification\nA: RNA processing and modification\n\n\nB\n1\nChromatin Structure and dynamics\nB: Chromatin Structure and dynamics\n\n\nC\n5\nEnergy production and conversion\nC: Energy production and conversion\n\n\nD\n5\nCell cycle control and mitosis\nD: Cell cycle control and mitosis\n\n\nG\n1\nCarbohydrate metabolism and transport\nG: Carbohydrate metabolism and transport\n\n\nI\n4\nLipid metabolism\nI: Lipid metabolism\n\n\nJ\n6\nTranlsation\nJ: Tranlsation\n\n\nK\n55\nTranscription\nK: Transcription\n\n\nL\n6\nReplication and repair\nL: Replication and repair\n\n\nM\n4\nCell wall/membrane/envelop biogenesis\nM: Cell wall/membrane/envelop biogenesis"
  },
  {
    "objectID": "lectures/plotting_omics_data.html#principal-component-analysis",
    "href": "lectures/plotting_omics_data.html#principal-component-analysis",
    "title": "Plotting Omics Data",
    "section": "3 Principal Component Analysis",
    "text": "3 Principal Component Analysis\nTypically, PCA is used for dimensionality reduction to get lower-dimensional data while keeping the most variation possible by taking only the first few principal components. In principle, SVD (singlular value decomposition) or eigenvalues of the data covariance matrix can be used to evaluate the principal components.\nFrom datacamp, The PCA can be more easily computed by following these five steps:\n\nNormalize data: As these data have different scales, performing PCA on them will result in a biased result. In order to ensure that each attribute contributes equally and to prevent one variable from dominating others, the data set needs to be normalized.\nComputing the covariable matrix from the normalized data. This is a symmetric matrix, and each element (i, j) corresponds to the covariance between variables i and j.\nGet Eigenvectors and eigenvalues: The term eigenvector refers to a direction in mathematics, such as ‚Äúvertical‚Äù or ‚Äú90 degrees‚Äù. By contrast, an eigenvalue represents how much variance there is in a given direction in the data. Therefore, each eigenvector has a corresponding eigenvalue.\nSelect the principal components: It‚Äôs about choosing the eigenvector with the highest eigenvalue that corresponds to the first principal component. The second principal component is the eigenvector with the second highest eigenvalue, etc.\nTransforming data into a new form: A new subspace is defined by the principal components, so the original data is re-oriented by multiplying it by the previously computed eigenvectors. As a result of this transformation, the original data doesn‚Äôt change, but instead provides a new perspective to better represent it.\n\nWe will demonstrate PCA on a pasilla data set (Brooks et al. 2010). This data set was obtained from an experiment on Drosophila melanogaster cell cultures that investigated the effects of knocking down the splicing factor pasilla using RNAi.\n\n# Load data set\ncts &lt;- read_delim(\"https://raw.githubusercontent.com/JirathNuan/r-handviz-workshop/main/datasets/cts.tsv\")\n\n# Prepare DESeq input, which is expecting a matrix of integers.\n1de_input &lt;- as.matrix(cts[,-1])\nrow.names(de_input)&lt;- cts$transcript_name\n# Remove NAs\n2de_input &lt;- de_input[complete.cases(de_input), ]\n\n# Show first 10 rows of the matrix\nkbl(head(de_input, 10))\n\n# Create sample metadata     \n3coldata &lt;- data.frame(sample = colnames(de_input),\n                      sample_group = gsub(\"[0-9]\", \"\", colnames(de_input)))\n\n\n# Show how experimental data looks like\nkbl(coldata)\n\n\n1\n\nLoad data set into cts data frame, and convert to matrix.\n\n2\n\nRemoving NA. The whole row will be deleted if NA is observed.\n\n3\n\nSample metadata should show a relationship between the sample name (from the matrix column), the sample group, and other experimental design.\n\n\n\n\n\n\n\n\ntreated1\ntreated2\ntreated3\nuntreated1\nuntreated2\nuntreated3\nuntreated4\n\n\n\n\nFBgn0000003\n0\n0\n1\n0\n0\n0\n0\n\n\nFBgn0000008\n140\n88\n70\n92\n161\n76\n70\n\n\nFBgn0000014\n4\n0\n0\n5\n1\n0\n0\n\n\nFBgn0000015\n1\n0\n0\n0\n2\n1\n2\n\n\nFBgn0000017\n6205\n3072\n3334\n4664\n8714\n3564\n3150\n\n\nFBgn0000018\n722\n299\n308\n583\n761\n245\n310\n\n\nFBgn0000022\n0\n0\n0\n0\n1\n0\n0\n\n\nFBgn0000024\n10\n7\n5\n10\n11\n3\n3\n\n\nFBgn0000028\n0\n1\n1\n0\n1\n0\n0\n\n\nFBgn0000032\n1698\n696\n757\n1446\n1713\n615\n672\n\n\n\n\n\n\nsample\nsample_group\n\n\n\n\ntreated1\ntreated\n\n\ntreated2\ntreated\n\n\ntreated3\ntreated\n\n\nuntreated1\nuntreated\n\n\nuntreated2\nuntreated\n\n\nuntreated3\nuntreated\n\n\nuntreated4\nuntreated\n\n\n\n\n\n\n\nThis workshop will demonstrate data normalization using DESeq2 library.\n\n# Create DESeq object by load matrix and experimental design\n1dds &lt;- DESeqDataSetFromMatrix(countData = de_input,\n                              colData = coldata,\n                              design= ~ sample_group)\n\n# Perform differential expression analysis\n2dds &lt;- DESeq(dds)\n\n# Create a normalized matrix of cts data set\n3cts_norm &lt;- counts(dds, normalized = TRUE)\n\n# Show how the data looks like\nhead(cts_norm) %&gt;% kbl()\n\n\n1\n\nCreate DESeq object using count matrix and sample metadata.\n\n2\n\nThis function is from DESeq2, to perform differential expression analysis based on the Negative Binomial (a.k.a. Gamma-Poisson) distribution. The analysis started with estimating size factors, estimating dispersion, and fitting the Negative Binomial GLM model and calculate Wald statistics.\n\n3\n\nCreate a matrix of normalized count from DESeq2 object after DE analysis.\n\n\n\n\n\n\n\n\ntreated1\ntreated2\ntreated3\nuntreated1\nuntreated2\nuntreated3\nuntreated4\n\n\n\n\nFBgn0000003\n0.0000000\n0.0000\n1.200981\n0.000000\n0.0000000\n0.000000\n0.000000\n\n\nFBgn0000008\n85.5968034\n115.5963\n84.068670\n80.824908\n89.7936241\n117.004615\n93.123591\n\n\nFBgn0000014\n2.4456230\n0.0000\n0.000000\n4.392658\n0.5577244\n0.000000\n0.000000\n\n\nFBgn0000015\n0.6114057\n0.0000\n0.000000\n0.000000\n1.1154487\n1.539534\n2.660674\n\n\nFBgn0000017\n3793.7726082\n4035.3632\n4004.070676\n4097.471407\n4860.0101913\n5486.900612\n4190.561607\n\n\nFBgn0000018\n441.4349433\n392.7648\n369.902150\n512.183926\n424.4282483\n377.185929\n412.404476\n\n\n\n\n\n\n\nThis step is to transform the count matrix through Rlog (regularized log) transforms. Which transform the original count data into log2 scale by fitting a model with a term for each sample and a prior distribution on the coefficients. Use before plotting PCA.\n\n# Plot PCA With pcaExplorer\n1rld_dds &lt;- rlogTransformation(dds)\n2pca_dds &lt;- pcaplot(\n  rld_dds,\n  intgroup = \"sample_group\",\n  ntop = Inf,\n  pcX = 1,\n  pcY = 2,\n  title = \"\",\n  text_labels = TRUE\n) +\n  scale_fill_npg() +\n  scale_color_npg() +\n  theme(legend.position = \"bottom\") +\n  coord_flip()\npca_dds\n\n\n1\n\nRlog (regularized log) transforms the original count data into log2 scale by fitting a model with a term for each sample and a prior distribution on the coefficients. Use before plotting PCA.\n\n2\n\nPlot PCA\n\n\n\n\n\n\n\nThis step is to examine the principal components and visualizing eigenvalues as a scree plot. A scree plot is used to determine the number of significant principal components in a set of data. It is a line graph that shows the eigenvalues of each component in descending order. This helps to identify which components are most important and which can be discarded.\nWe‚Äôll demonstrate a scree plot using fviz_eig() function from factoextra library.\n\n# Scree plot\npcaobj_dds &lt;- prcomp(t(assay(rld_dds)))\n\n# Visualizing scree plot\nfviz_eig(pcaobj_dds, \n         addlabels = TRUE, \n         barfill = pal_npg()(1),\n         barcolor = \"black\",\n         title = \"Proportion of explained proportion of variance - cts data set\",\n         ggtheme = theme_gray())\n\n\n\n\nThen, extract genes that are mostly contributed in the principal components. By extracting genes that are primarily responsible for the principal components, it becomes easier to understand the underlying structure of the data and identify potential observations that are associated with certain variables.\n\n# extract the table of the genes with high loadings\ntop100_pc &lt;- hi_loadings(pcaobj_dds,\n                         topN = 100,\n                         exprTable = counts(dds))\n\n# Show how experimental data looks like\nhead(top100_pc) %&gt;% kbl() %&gt;% kable_styling(full_width = FALSE)\n\n\n\n\n\ntreated1\ntreated2\ntreated3\nuntreated1\nuntreated2\nuntreated3\nuntreated4\n\n\n\n\nFBgn0044047\n348\n118\n151\n428\n667\n200\n235\n\n\nFBgn0037683\n1496\n710\n918\n1868\n2848\n1090\n1641\n\n\nFBgn0038381\n150\n74\n79\n260\n309\n121\n178\n\n\nFBgn0040752\n5117\n2778\n2786\n5293\n10550\n4998\n4235\n\n\nFBgn0029801\n1628\n788\n917\n1802\n3677\n1256\n1313\n\n\nFBgn0037635\n167\n71\n92\n229\n378\n139\n181\n\n\n\n\n\n\n\nThen, plot PCA biplotgenespca() by compute the principal components of the genes, eventually displaying the samples as in a typical biplot visualization.\n\ngroups_cts &lt;- colData(dds)$sample_group\n\ncols_cts &lt;- scales::hue_pal()(2)[groups_cts]\n\n# with many genes, do not plot the labels of the genes\ngenespca(\n  rld_dds,\n  ntop = 100,\n  choices = c(1, 2),\n  arrowColors = cols_cts,\n  groupNames = groups_cts,\n  useRownamesAsLabels = FALSE,\n  varname.size = 5,\n  biplot = TRUE,\n  alpha = 0.5,\n  point_size = 2.5\n)\n\n\n\n\nPlots the distribution of expression values, either with density lines, boxplots or violin plots.\n\ndistro_expr(rld_dds, plot_type = \"violin\") + \n  scale_fill_npg() + \n  scale_color_npg()\ndistro_expr(rld_dds, plot_type = \"boxplot\") + \n  scale_fill_npg() + \n  scale_color_npg()\n\n\n\n\n\n\n\n\n\n\n\n\nSee more usage of pcaExplorer: https://federicomarini.github.io/pcaExplorer/articles/pcaExplorer.html#functions-exported-by-the-package-for-standalone-usage"
  },
  {
    "objectID": "lectures/plotting_omics_data.html#hierarchical-clustering-analysis-heat-maps",
    "href": "lectures/plotting_omics_data.html#hierarchical-clustering-analysis-heat-maps",
    "title": "Plotting Omics Data",
    "section": "4 Hierarchical Clustering Analysis (Heat maps)",
    "text": "4 Hierarchical Clustering Analysis (Heat maps)\nHierarchical clustering is an unsupervised machine learning algorithm. It is used to group data points into clusters based on their similarity. The algorithm gradually merges or splits clusters after creating a hierarchy. As a result, a dendrogram shows which points are in each cluster and how similar they are.\nWe‚Äôll demonstrate the hierarchical clustering and plot heat map using pheatmap().\n\n# Create annotation column\nannot_column &lt;- data.frame(sample = colnames(top100_pc),\n                           group = gsub(\"[0-9]\", \"\", colnames(top100_pc))) %&gt;% \n  column_to_rownames(var = \"sample\")\n\nannot_column %&gt;% kbl()\n\n\n\n\n\ngroup\n\n\n\n\ntreated1\ntreated\n\n\ntreated2\ntreated\n\n\ntreated3\ntreated\n\n\nuntreated1\nuntreated\n\n\nuntreated2\nuntreated\n\n\nuntreated3\nuntreated\n\n\nuntreated4\nuntreated\n\n\n\n\n\n\n# Create a list of annotation color\nsample_pal &lt;- pal_npg()(2)\nannot_colors &lt;- list(group = c(treated = sample_pal[1],\n                               untreated = sample_pal[2]))\n\n\nHeat map of Top 100 genes that are mostly contributed in the principal components above.\n\n\n# Heatmap of the top 100 principal components\nhm_top100pc &lt;- pheatmap(\n  top100_pc,\n  scale = \"row\",\n  color = colorRampPalette(rev(brewer.pal(n = 7, name = \"RdBu\")))(100),\n  show_rownames = FALSE,\n  name = \"Normalized count\",\n  clustering_distance_rows = \"euclidean\",\n  clustering_distance_cols = \"euclidean\",\n  clustering_method = \"complete\",\n  annotation_col = annot_column,\n  annotation_names_col = FALSE,\n  annotation_colors = annot_colors,\n  cutree_rows = 3,\n  annotation_legend = FALSE\n)\nhm_top100pc\n\n\n\n\n\nHeat map of differentially expressed genes.\n\n\n# Identify differentially expressed genes\ndds_result &lt;- results(object = dds,\n                      contrast = c(\"sample_group\", \"untreated\", \"treated\"),\n                      tidy = TRUE,\n                      pAdjustMethod = \"fdr\")\n\nFilter DEG, we‚Äôll use absolute log2FC &gt; 1 and FDR &lt; 0.05\n\ndds_result_deg &lt;- dds_result %&gt;% \n  filter(padj &lt; 0.05 & abs(log2FoldChange) &gt; 1)\n\n# Extract count matrix of DEGenes\ndeg_norm_count &lt;- cts_norm[rownames(cts_norm) %in% dds_result_deg$row, ]\n\n# Plot heatmap of DEGs\n# Heatmap of the top 100 principal components\nhm_deg &lt;- pheatmap(\n  deg_norm_count,\n  scale = \"row\",\n  color = colorRampPalette(rev(brewer.pal(n = 7, name = \"RdBu\")))(100),\n  show_rownames = FALSE,\n  name = \"Normalized count\",\n  clustering_distance_rows = \"euclidean\",\n  clustering_distance_cols = \"euclidean\",\n  clustering_method = \"complete\",\n  annotation_col = annot_column,\n  annotation_names_col = FALSE,\n  annotation_colors = annot_colors,\n  cutree_rows = 2,\n  annotation_legend = FALSE)\nhm_deg\n\n\n\n\n\nSee more pheatmap() usage: https://www.reneshbedre.com/blog/heatmap-with-pheatmap-package-r.html"
  },
  {
    "objectID": "lectures/plotting_omics_data.html#volcano-plot",
    "href": "lectures/plotting_omics_data.html#volcano-plot",
    "title": "Plotting Omics Data",
    "section": "5 Volcano Plot",
    "text": "5 Volcano Plot\n\nvolcano_deg &lt;- dds_result %&gt;% \n  mutate(Expression = case_when(\n      log2FoldChange &gt;= 1 & padj &lt;= 0.05 ~ \"Upregulated\",\n      log2FoldChange &lt;= -1 & padj &lt;= 0.05 ~ \"Downregulated\",\n      TRUE ~ \"Unchanged\"))\n\np_volcano &lt;- EnhancedVolcano(\n  volcano_deg,\n  lab = volcano_deg$row,\n  x = 'log2FoldChange',\n  y = 'padj',\n  xlim = c(-5,5),\n  ylab = bquote( ~ -Log[10] ~ italic(FDR)),\n  title = NULL,\n  caption = NULL,\n  subtitle = NULL,\n  pCutoff = 0.05,\n  pointSize = 3,\n  labSize = 3,\n  col = c(\"grey50\", \"dodgerblue3\", \"dodgerblue3\", \"firebrick2\"),\n  legendLabels = c(\"NS\", \n                   expression(abs(log[2] ~ FC) &gt; 1),\n                   \"FDR &lt; 0.05\",\n                   expression(Pvalue &lt; 0.05 ~ and ~ abs(log[2] ~ FC) &gt; 1))) +\n  theme_minimal() +\n  theme(legend.position = \"bottom\",\n        panel.border = element_rect(fill = NA, color = \"black\"),\n        panel.grid = element_blank())\n\n\np_volcano\n\n\n\n\n\nSee more EnhancedVolcano() usage: https://bioconductor.org/packages/devel/bioc/vignettes/EnhancedVolcano/inst/doc/EnhancedVolcano.html"
  },
  {
    "objectID": "lectures/plotting_omics_data.html#venn-diagram-and-upset-plot",
    "href": "lectures/plotting_omics_data.html#venn-diagram-and-upset-plot",
    "title": "Plotting Omics Data",
    "section": "6 Venn Diagram and Upset Plot",
    "text": "6 Venn Diagram and Upset Plot\n\n6.1 Plotting Venn diagram with ggvenn\n\n# Load data\nmouse_hallmarks &lt;- read_delim(\"https://github.com/JirathNuan/r-handviz-workshop/raw/main/datasets/mouse_msigdb_6hallmarks.txt\")\n\n# Split into list\nlst_mouse_hallmark &lt;- as.list(mouse_hallmarks)\n# remove NAs\nlst_mouse_hallmark &lt;- lapply(lst_mouse_hallmark, na.omit)\n\n# Chart\nggvenn(\n  lst_mouse_hallmark, \n  fill_color = pal_npg()(6),\n  stroke_size = 0.5, \n  set_name_size = 3\n  )\n\n\n\n\n\n\n\n\n\n\nVenn diagram limitation\n\n\n\nVenn diagrams are simple and easy to interpret, however, ggvenn only allows the visualization of four features at a time. As a result, an alternative of Venn diagram has been developed.\n\n\n\n\n6.2 Venn diagram alternative: Upset Plot\nUpSet plots are more efficient than Venn Diagrams at visualizing intersections of multiple sets. They are particularly useful when analyzing large datasets with many variables. They help to identify patterns and relationships between different sets more quickly and easily than other visualizations.\nThere are 3 different modes of upset plot, distinct (default), intersect, and union. Here we‚Äôll only demonstrate the default mode.\n\nset.seed(123)\n\n# Make present-absent matrix of data list\nmouse_hm_mat01 &lt;- list_to_matrix(lst_mouse_hallmark)\n# Show how the combination matrix looks like\nhead(mouse_hm_mat01) %&gt;% kbl()\n\n\n\n\n\nG2M checkpoint\nApoptosis\nDNA Repair\nWNT/B-Catenin Signaling\nHedgehog Signaling\nTGF_BETA_SIGNALING\n\n\n\n\nAaas\n0\n0\n1\n0\n0\n0\n\n\nAbl1\n1\n0\n0\n0\n0\n0\n\n\nAche\n0\n0\n0\n0\n1\n0\n\n\nAcvr1\n0\n0\n0\n0\n0\n1\n\n\nAda\n0\n0\n1\n0\n0\n0\n\n\nAdam17\n0\n0\n0\n1\n0\n0\n\n\n\n\n\n\n# Make the combination matrix\ncomb_mat &lt;- make_comb_mat(lst_mouse_hallmark)\ncomb_mat\n\nA combination matrix with 6 sets and 18 combinations.\n  ranges of combination set size: c(1, 183).\n  mode for the combination size: distinct.\n  sets are on rows.\n\nTop 8 combination sets are:\n  G2M checkpoint Apoptosis DNA Repair WNT/B-Catenin Signaling Hedgehog Signaling TGF_BETA_SIGNALING   code size\n               x                                                                                    100000  183\n                         x                                                                          010000  147\n                                    x                                                               001000  143\n                                                                                                  x 000001   45\n                                                            x                                       000100   31\n                                                                               x                    000010   31\n               x         x                                                                          110000    4\n                         x                                                                        x 010001    4\n\nSets are:\n                      set size\n           G2M checkpoint  195\n                Apoptosis  161\n               DNA Repair  148\n  WNT/B-Catenin Signaling   42\n       Hedgehog Signaling   36\n       TGF_BETA_SIGNALING   53\n\n\nReferred from a full guide of complexHeatmap: The UpSet plot visualizes the size of each combination set. With the binary code of each combination set, we can calculate the size. There are three modes.\n\n\n\nFigure from: https://jokergoo.github.io/ComplexHeatmap-reference/book/upset-plot.html#upset-plot\n\n\nPlot upset plot\n\npal_upset &lt;- pal_npg()(4)\n# Plot upset following the default upset mode.\nupset_mouse_hm &lt;-\n  UpSet(\n    comb_mat,\n    comb_col = pal_upset[1],\n    row_names_gp = gpar(fontsize = 10),\n    right_annotation = upset_right_annotation(\n      comb_mat,\n      gp = gpar(fill = pal_upset[2]),\n      add_numbers = TRUE\n    ),\n    top_annotation = upset_top_annotation(\n      comb_mat,\n      gp = gpar(fill = pal_upset[1]),\n      add_numbers = TRUE\n    )\n  )\nupset_mouse_hm\n\n\n\n\n\nSee more UpSet() usage from a complete reference of complexHeatmap: https://jokergoo.github.io/ComplexHeatmap-reference/book/upset-plot.html#upset-plot"
  },
  {
    "objectID": "lectures/plotting_omics_data.html#ggplot2-based-publication-ready-plots-with-ggpubr",
    "href": "lectures/plotting_omics_data.html#ggplot2-based-publication-ready-plots-with-ggpubr",
    "title": "Plotting Omics Data",
    "section": "7 ggplot2 Based Publication Ready Plots with ggpubr",
    "text": "7 ggplot2 Based Publication Ready Plots with ggpubr\n\n# Load dataset\nmouseLiver_ctg &lt;- read_csv(\"https://github.com/JirathNuan/r-handviz-workshop/raw/main/datasets/mouseLiver_data_ClinicalTraits.csv\")\n\n# Inspect the data\nhead(mouseLiver_ctg) %&gt;% kbl()\n\n\n\n\nMice\nStrain\nsex\nweight_g\nlength_cm\nab_fat\nother_fat\ntotal_fat\n100xfat_weight\nTrigly\nTotal_Chol\nHDL_Chol\nUC\nFFA\nGlucose\nLDL_plus_VLDL\nMCP_1_phys\nInsulin_ug_l\nGlucose_Insulin\nLeptin_pg_ml\nAdiponectin\nAortic lesions\n\n\n\n\nF2_290\nBxH ApoE-/-, F2\nFemale\n36.9\n9.9\n2.53\n2.26\n4.79\n12.981030\n53\n1167\n50\n484\n121\n437\n1117\n175.850\n924\n0.4729437\n245462.00\n11.274\n496250\n\n\nF2_291\nBxH ApoE-/-, F2\nFemale\n48.5\n10.7\n2.90\n2.97\n5.87\n12.103093\n61\n1230\n32\n592\n173\n572\n1198\n92.430\n5781\n0.0989448\n84420.88\n7.099\nNA\n\n\nF2_292\nBxH ApoE-/-, F2\nMale\n45.7\n10.4\n1.04\n2.31\n3.35\n7.330416\n41\n1285\n81\n460\n96\n497\n1204\n196.398\n2074\n0.2396336\n105889.76\n5.795\n218500\n\n\nF2_293\nBxH ApoE-/-, F2\nMale\n50.3\n10.9\n0.91\n1.89\n2.80\n5.566600\n271\n1299\n64\n476\n122\n553\n1235\n97.466\n11874\n0.0465723\n100398.68\n5.495\n61250\n\n\nF2_294\nBxH ApoE-/-, F2\nMale\n44.8\n9.8\n1.22\n2.47\n3.69\n8.236607\n114\n1410\n50\n516\n118\n535\n1360\n95.452\n9181\n0.0582725\n130846.30\n6.868\n243750\n\n\nF2_295\nBxH ApoE-/-, F2\nMale\n39.2\n10.2\n3.06\n2.49\n5.55\n14.158163\n72\n1533\n18\n620\n106\n382\n1515\n144.270\n485\n0.7876289\n75166.22\n17.328\n104250\n\n\n\n\n\n\n\n\n7.1 Histogram\n\ngghistogram(\n  mouseLiver_ctg,\n  x = \"weight_g\",\n  add = \"mean\",\n  rug = TRUE,\n  color = \"sex\",\n  fill = \"sex\",\n  bins = 30,\n  palette = \"npg\",\n  xlab = \"Weight (g)\",\n  ylab = \"Frequency\"\n)\n\n\n\n\n\n\n7.2 Density plot\n\nggdensity(\n  mouseLiver_ctg,\n  x = \"weight_g\",\n  add = \"mean\",\n  rug = TRUE,\n  color = \"sex\",\n  fill = \"sex\",\n  palette = \"npg\",\n  xlab = \"Weight (g)\",\n  ylab = \"Frequency\"\n)\n\n\n\n\n\n\n7.3 Simple box plot\n\np_boxplot &lt;- ggboxplot(ToothGrowth, x = \"supp\", y = \"len\",\n          color = \"supp\", palette = \"npg\",\n          add = \"jitter\",\n          xlab = \"Supplement type\",\n          ylab = \"Tooth length\")\np_boxplot\n\n\n\n\nAdding statistical significance to the plot\n\nPairwise comparison\n\n\n# Try to calculate stat first\ncompare_means(len ~ supp, data = ToothGrowth, method = \"anova\")\ncompare_means(len ~ supp, data = ToothGrowth, method = \"wilcox.test\")\n# Plot box plot with significance\np_boxplot + stat_compare_means(method = \"anova\")\np_boxplot + stat_compare_means(method = \"wilcox.test\")\n# Change style of singnificance notation\np_boxplot + stat_compare_means(method = \"anova\",\n                               aes(label = ..p.signif..),\n                               label.x = 1.5,\n                               label.y = 40)\np_boxplot + stat_compare_means(method = \"wilcox.test\",\n                               aes(label = \"p.signif\"),\n                               label.x = 1.5,\n                               label.y = 40)\n\n\n\n# A tibble: 1 √ó 6\n  .y.        p p.adj p.format p.signif method\n  &lt;chr&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt; \n1 len   0.0604  0.06 0.06     ns       Anova \n\n\n# A tibble: 1 √ó 8\n  .y.   group1 group2      p p.adj p.format p.signif method  \n  &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;   \n1 len   OJ     VC     0.0645 0.064 0.064    ns       Wilcoxon\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCompare more than two groups\n\n\n# Global test\ncompare_means(len ~ dose,  data = ToothGrowth, method = \"anova\")\n# Default method = \"kruskal.test\" for multiple groups\nggboxplot(ToothGrowth, x = \"dose\", y = \"len\",\n          fill = \"dose\", palette = \"npg\")+\n  stat_compare_means()\n# Change method to anova\nggboxplot(ToothGrowth, x = \"dose\", y = \"len\",\n          fill = \"dose\", palette = \"npg\")+\n  stat_compare_means(method = \"anova\")\n\n\n\n# A tibble: 1 √ó 6\n  .y.          p   p.adj p.format p.signif method\n  &lt;chr&gt;    &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt; \n1 len   9.53e-16 9.5e-16 9.5e-16  ****     Anova \n\n\n\n\n\n\n\n\n\n\n\n\n\n# Perorm pairwise comparisons\ncompare_means(len ~ dose,  data = ToothGrowth)\n\n# A tibble: 3 √ó 8\n  .y.   group1 group2            p      p.adj p.format p.signif method  \n  &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;         &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;   \n1 len   0.5    1      0.00000702   0.000014   7.0e-06  ****     Wilcoxon\n2 len   0.5    2      0.0000000841 0.00000025 8.4e-08  ****     Wilcoxon\n3 len   1      2      0.000177     0.00018    0.00018  ***      Wilcoxon\n\n# Visualize: Specify the comparisons you want\nmy_comparisons &lt;- list(c(\"0.5\", \"1\"), c(\"1\", \"2\"), c(\"0.5\", \"2\"))\n\nggboxplot(\n  ToothGrowth,\n  x = \"dose\",\n  y = \"len\",\n  fill = \"dose\",\n  palette = \"npg\") +\n  stat_compare_means(comparisons = my_comparisons) + # Add pairwise comparisons p-value\n  stat_compare_means(label.y = 50)     # Add global p-value\n\n\n\n\n\nMultiple pairwise tests against a reference group\n\n\n# Pairwise comparison against reference\ncompare_means(len ~ dose,\n              data = ToothGrowth,\n              ref.group = \"0.5\",\n              method = \"t.test\")\n\n# A tibble: 2 √ó 8\n  .y.   group1 group2        p    p.adj p.format p.signif method\n  &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt; \n1 len   0.5    1      1.27e- 7 1.3 e- 7 1.3e-07  ****     T-test\n2 len   0.5    2      4.40e-14 8.80e-14 4.4e-14  ****     T-test\n\n# Visualize\nggboxplot(\n  ToothGrowth,\n  x = \"dose\",\n  y = \"len\",\n  fill = \"dose\",\n  palette = \"npg\") +\n  stat_compare_means(method = \"anova\", label.y = 40) +      # Add global p-value\n  stat_compare_means(label = \"p.signif\",\n                     method = \"t.test\",\n                     ref.group = \"0.5\")                    # Pairwise comparison against reference\n\n\n\n\nMultiple grouping variables\n\ncompare_means(len ~ supp, data = ToothGrowth, group.by = \"dose\")\n\n# A tibble: 3 √ó 9\n   dose .y.   group1 group2       p p.adj p.format p.signif method  \n  &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;   \n1   0.5 len   OJ     VC     0.0232  0.046 0.023    *        Wilcoxon\n2   1   len   OJ     VC     0.00403 0.012 0.004    **       Wilcoxon\n3   2   len   OJ     VC     1       1     1.000    ns       Wilcoxon\n\n# Box plot facetted by \"dose\"\np_box &lt;- ggboxplot(\n  ToothGrowth,\n  x = \"supp\",\n  y = \"len\",\n  color = \"supp\",\n  palette = \"jco\",\n  add = \"jitter\",\n  facet.by = \"dose\",\n  short.panel.labs = FALSE\n)\n# Use only p.format as label. Remove method name.\np_box + stat_compare_means(label = \"p.format\")\n\n\n\n\n\n\n7.4 Bar and line plots (one grouping variable):\n\nggbarplot(\n  ToothGrowth,\n  x = \"dose\",\n  y = \"len\",\n  add = \"mean_se\",\n  fill = \"supp\",\n  palette = \"npg\",\n  color = \"black\",\n  position = position_dodge(0.8)) +\n  stat_compare_means(aes(group = supp), label = \"p.signif\", label.y = 29)\nggline(\n  ToothGrowth,\n  x = \"dose\",\n  y = \"len\",\n  add = \"mean_se\",\n  color = \"supp\",\n  palette = \"npg\") +\n  stat_compare_means(aes(group = supp),\n                     label = \"p.signif\",\n                     label.y = c(16, 25, 29))\n\n\n\n\n\n\n\n\n\n\n\n\n\n7.5 Scatter plot\n\np4 &lt;- ggscatter(\n  mtcars,\n  x = \"wt\",\n  y = \"mpg\",\n  fill = \"mpg\",\n  size = 4,\n  shape = 21) +\n  gradient_fill(c(\"blue\", \"white\", \"red\"))\np4\n\n\n\n\n\nMore usage of ggpubr: http://www.sthda.com/english/articles/24-ggpubr-publication-ready-plots/76-add-p-values-and-significance-levels-to-ggplots/."
  },
  {
    "objectID": "lectures/plotting_omics_data.html#session-info",
    "href": "lectures/plotting_omics_data.html#session-info",
    "title": "Plotting Omics Data",
    "section": "8 Session info",
    "text": "8 Session info\n\nsessionInfo()\n\nR version 4.3.0 (2023-04-21 ucrt)\nPlatform: x86_64-w64-mingw32/x64 (64-bit)\nRunning under: Windows 11 x64 (build 22621)\n\nMatrix products: default\n\n\nlocale:\n[1] LC_COLLATE=English_United States.utf8 \n[2] LC_CTYPE=English_United States.utf8   \n[3] LC_MONETARY=English_United States.utf8\n[4] LC_NUMERIC=C                          \n[5] LC_TIME=English_United States.utf8    \n\ntime zone: Asia/Bangkok\ntzcode source: internal\n\nattached base packages:\n[1] grid      stats4    stats     graphics  grDevices utils     datasets \n[8] methods   base     \n\nother attached packages:\n [1] ggpubr_0.6.0                ggvenn_0.1.10              \n [3] EnhancedVolcano_1.18.0      ggrepel_0.9.3              \n [5] RColorBrewer_1.1-3          ComplexHeatmap_2.16.0      \n [7] ggsci_3.0.0                 factoextra_1.0.7           \n [9] pcaExplorer_2.26.1          DESeq2_1.40.1              \n[11] SummarizedExperiment_1.30.1 Biobase_2.60.0             \n[13] MatrixGenerics_1.12.0       matrixStats_0.63.0         \n[15] GenomicRanges_1.52.0        GenomeInfoDb_1.36.0        \n[17] IRanges_2.34.0              S4Vectors_0.38.1           \n[19] BiocGenerics_0.46.0         openxlsx_4.2.5.2           \n[21] kableExtra_1.3.4            lubridate_1.9.2            \n[23] forcats_1.0.0               stringr_1.5.0              \n[25] dplyr_1.1.2                 purrr_1.0.1                \n[27] readr_2.1.4                 tidyr_1.3.0                \n[29] tibble_3.2.1                ggplot2_3.4.2              \n[31] tidyverse_2.0.0            \n\nloaded via a namespace (and not attached):\n  [1] splines_4.3.0           later_1.3.1             bitops_1.0-7           \n  [4] filelock_1.0.2          graph_1.78.0            XML_3.99-0.14          \n  [7] lifecycle_1.0.3         rstatix_0.7.2           topGO_2.52.0           \n [10] doParallel_1.0.17       vroom_1.6.3             lattice_0.21-8         \n [13] crosstalk_1.2.0         backports_1.4.1         dendextend_1.17.1      \n [16] magrittr_2.0.3          limma_3.56.1            plotly_4.10.1          \n [19] rmarkdown_2.21          yaml_2.3.7              shinyBS_0.61.1         \n [22] httpuv_1.6.10           NMF_0.26                zip_2.3.0              \n [25] DBI_1.1.3               abind_1.4-5             zlibbioc_1.46.0        \n [28] rvest_1.0.3             RCurl_1.98-1.12         rappdirs_0.3.3         \n [31] circlize_0.4.15         seriation_1.4.2         GenomeInfoDbData_1.2.10\n [34] AnnotationForge_1.42.0  genefilter_1.82.1       pheatmap_1.0.12        \n [37] annotate_1.78.0         svglite_2.1.1           codetools_0.2-19       \n [40] DelayedArray_0.26.2     DT_0.27                 xml2_1.3.4             \n [43] shape_1.4.6             tidyselect_1.2.0        GOstats_2.66.0         \n [46] farver_2.1.1            viridis_0.6.3           TSP_1.2-4              \n [49] BiocFileCache_2.8.0     base64enc_0.1-3         webshot_0.5.4          \n [52] jsonlite_1.8.4          GetoptLong_1.0.5        ellipsis_0.3.2         \n [55] survival_3.5-5          iterators_1.0.14        systemfonts_1.0.4      \n [58] foreach_1.5.2           tools_4.3.0             progress_1.2.2         \n [61] Rcpp_1.0.10             glue_1.6.2              gridExtra_2.3          \n [64] xfun_0.39               ca_0.71.1               shinydashboard_0.7.2   \n [67] withr_2.5.0             BiocManager_1.30.20     Category_2.66.0        \n [70] fastmap_1.1.1           fansi_1.0.4             SparseM_1.81           \n [73] digest_0.6.31           timechange_0.2.0        R6_2.5.1               \n [76] mime_0.12               colorspace_2.1-0        GO.db_3.17.0           \n [79] biomaRt_2.56.0          RSQLite_2.3.1           threejs_0.3.3          \n [82] utf8_1.2.3              generics_0.1.3          data.table_1.14.8      \n [85] prettyunits_1.1.1       httr_1.4.6              htmlwidgets_1.6.2      \n [88] S4Arrays_1.0.1          pkgconfig_2.0.3         gtable_0.3.3           \n [91] blob_1.2.4              registry_0.5-1          XVector_0.40.0         \n [94] htmltools_0.5.5         carData_3.0-5           RBGL_1.76.0            \n [97] clue_0.3-64             GSEABase_1.62.0         scales_1.2.1           \n[100] png_0.1-8               knitr_1.42              rstudioapi_0.14        \n[103] rjson_0.2.21            tzdb_0.3.0              reshape2_1.4.4         \n[106] curl_5.0.0              shinyAce_0.4.2          GlobalOptions_0.1.2    \n[109] cachem_1.0.8            parallel_4.3.0          AnnotationDbi_1.62.1   \n[112] pillar_1.9.0            vctrs_0.6.2             promises_1.2.0.1       \n[115] car_3.1-2               dbplyr_2.3.2            xtable_1.8-4           \n[118] cluster_2.1.4           Rgraphviz_2.44.0        evaluate_0.21          \n[121] cli_3.6.1               locfit_1.5-9.7          compiler_4.3.0         \n[124] rlang_1.1.1             crayon_1.5.2            rngtools_1.5.2         \n[127] ggsignif_0.6.4          heatmaply_1.4.2         labeling_0.4.2         \n[130] plyr_1.8.8              stringi_1.7.12          viridisLite_0.4.2      \n[133] gridBase_0.4-7          BiocParallel_1.34.1     assertthat_0.2.1       \n[136] munsell_0.5.0           Biostrings_2.68.0       lazyeval_0.2.2         \n[139] pacman_0.5.1            Matrix_1.5-4            hms_1.1.3              \n[142] bit64_4.0.5             KEGGREST_1.40.0         shiny_1.7.4            \n[145] highr_0.10              broom_1.0.4             igraph_1.4.2           \n[148] memoise_2.0.1           bit_4.0.5"
  },
  {
    "objectID": "lectures/arranging_plots.html",
    "href": "lectures/arranging_plots.html",
    "title": "Arranging Multiple Plots",
    "section": "",
    "text": "# Load packages\npacman::p_load(\n  \"tidyverse\",\n  \"cowplot\",\n  \"grid\"\n)"
  },
  {
    "objectID": "lectures/arranging_plots.html#example-differential-gene-expression-analysis-in-pasilla-data-set",
    "href": "lectures/arranging_plots.html#example-differential-gene-expression-analysis-in-pasilla-data-set",
    "title": "Arranging Multiple Plots",
    "section": "1 Example: Differential Gene Expression Analysis in pasilla data set",
    "text": "1 Example: Differential Gene Expression Analysis in pasilla data set\nOur goal in this section is to combine the results from the previous section into one image. We will use PCA plot pca_dds, DEG heat map hm_deg, and volcano plot p_volcano. Your first step should be to ensure that all plot objects are available in your R environment. To make it easier to arrange in this chapter.\nIt is also important to make sure that all plots are gg objects. To do so, simply type class() followed by the plot object as follows.\n\n# Check the class of the plots\nclass(pca_dds)\nclass(hm_deg)\nclass(p_volcano)\n\nAs we can see the hm_deg that is generated by pheatmap() function of ComplexHeatmap library is different from the other plots. In order to make it compatible with other ggplot objects, we need to modify it using grid.grabExpr() of the ‚Äògrid‚Äô library. The following functions allow you to create a ‚Äúgrob‚Äù, ‚ÄúgTree‚Äù, or ‚ÄúgList‚Äù object that is compatible with ggplot2.\n\ngrob_hm &lt;- grid.grabExpr(draw(hm_deg))\n\n# Check class of the plot object again\nclass(grob_hm)\n\nAll plots can now be arranged together.\n\nLet‚Äôs start by combining PCA and volcano plots.\n\n\np_volc_pca &lt;- plot_grid(\n  pca_dds + theme(legend.position = \"none\"), \n  p_volcano + theme(legend.position = \"none\"), \n  nrow = 2, labels = \"AUTO\")\n\n\nCombine legend of the PCA and volcano using get_legend().\n\n\nlegend_pca &lt;- get_legend(pca_dds)\nlegend_volcano &lt;- get_legend(p_volcano)\n\n\nPut the first two plots together with the legends\n\n\np_volc_pca_lgd &lt;- plot_grid(p_volc_pca, \n                            legend_pca,\n                            legend_volcano,\n                            nrow = 3,\n                            rel_heights = c(1, 0.05, 0.05))\n\n\nThen combine with heat map\n\n\np_all &lt;- plot_grid(p_volc_pca_lgd,\n                   grob_hm,\n                   ncol = 2,\n                   labels = c(\"\", \"C\"),\n                   rel_widths = c(0.5, 0.5)) +\n  theme(panel.background = element_rect(fill = \"white\", color = NA))\n\n\nSave the plot\n\n\n# Save as PDF\nggsave(filename = \"DEG_plots_volc_pca_hm.pdf\",\n      plot = p_all,\n      scale = 1,\n      width = 10,\n      height = 10,\n      units = \"in\",\n      dpi = 400)\n\n# save as PNG\nggsave(filename = \"DEG_plots_volc_pca_hm.png\",\n      plot = p_all,\n      scale = 1,\n      width = 10,\n      height = 10,\n      units = \"in\",\n      dpi = 400)\n\n ## Practice"
  }
]